{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用python写网络爬虫\n",
    "\n",
    "## Web Scraping with Python\n",
    "\n",
    "【澳】 Richard Lawson著  \n",
    "李斌 译  \n",
    "中国工信出版集团 人民邮电出版社  \n",
    "2016年9月第1版\n",
    "\n",
    "豆瓣： \n",
    "[用Python写网络爬虫 (豆瓣)](https://book.douban.com/subject/26869992/)\n",
    "\n",
    "别人的读书笔记：  \n",
    "\n",
    "[《web scraping with python》（用Python写网络爬虫）读书笔记 - 简书](https://www.jianshu.com/p/26e7925177bb)  \n",
    "[《用Python写网络爬虫》读书笔记 | Pythoner](http://www.pythoner.com/495.html)  \n",
    "[《用python写网络爬虫》学习心得笔记 - 知乎](https://zhuanlan.zhihu.com/p/23957531)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 背景调研——爬取网站之前的先期了解\n",
    "\n",
    "1. 检查robots.txt  \n",
    "robots.txt可以让爬虫了解爬取该网站时存在哪些限制。检查robots.txt可以最小化爬虫被封禁的可能，还能发现和网站结构相关的线索。  \n",
    "关于robots.txt的更多信息：[Web机器人页面](http://www.robotstxt.org/robotstxt.html)\n",
    "\n",
    "2. 检查网站地图  \n",
    "网站提供的sitemap文件可以帮爬虫定位网站最新的内容，而无须爬取每一个网页。不过该文件经常存在缺失、过期或不完整的问题。  \n",
    "网站地图标准的定义：[sitemaps.org - Protocol](https://www.sitemaps.org/protocol.html)\n",
    "\n",
    "3. 估算网站大小  \n",
    "目标网站的大小会影响我们如何进行爬取。估算网站大小的一个简便方法是检查Google爬虫的结果，因为Google很可能已经爬取过我们感兴趣的网站。site:url\n",
    "\n",
    "4. 识别网站所用技术  \n",
    "构建网站所使用的技术类型也会对我们如何爬取产生影响。builtwith模块可以检查网站构建的技术类型。  \n",
    "\n",
    "5. 寻找网站所有者  \n",
    "对一些网站，我们可能会关心其所有者是谁。比如，若已知网站所有者会封禁网络爬虫，那就最好把下载速度控制得更加保守一些。为了找到网站的所有者，可以使用WHOIS协议查询域名的注册者是谁。安装模块python-whois，使用时`import whois`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtwith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web-servers': ['Nginx'],\n",
       " 'web-frameworks': ['Web2py', 'Twitter Bootstrap'],\n",
       " 'programming-languages': ['Python'],\n",
       " 'javascript-frameworks': ['jQuery', 'Modernizr', 'jQuery UI']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builtwith.parse('http://example.webscraping.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'font-scripts': ['Font Awesome'],\n",
       " 'javascript-frameworks': ['Moment.js', 'jQuery'],\n",
       " 'web-frameworks': ['Pure CSS', 'Twitter Bootstrap']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builtwith.parse('http://www.engine3d.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builtwith.parse('https://www.baidu.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web-servers': ['Tengine']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builtwith.parse('https://www.taobao.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"domain_name\": [\n",
      "    \"APPSPOT.COM\",\n",
      "    \"appspot.com\"\n",
      "  ],\n",
      "  \"registrar\": \"MarkMonitor, Inc.\",\n",
      "  \"whois_server\": \"whois.markmonitor.com\",\n",
      "  \"referral_url\": null,\n",
      "  \"updated_date\": [\n",
      "    \"2019-02-06 10:33:49\",\n",
      "    \"2019-02-06 02:33:49\"\n",
      "  ],\n",
      "  \"creation_date\": [\n",
      "    \"2005-03-10 02:27:55\",\n",
      "    \"2005-03-09 18:27:55\"\n",
      "  ],\n",
      "  \"expiration_date\": [\n",
      "    \"2020-03-10 01:27:55\",\n",
      "    \"2020-03-09 00:00:00\"\n",
      "  ],\n",
      "  \"name_servers\": [\n",
      "    \"NS1.GOOGLE.COM\",\n",
      "    \"NS2.GOOGLE.COM\",\n",
      "    \"NS3.GOOGLE.COM\",\n",
      "    \"NS4.GOOGLE.COM\",\n",
      "    \"ns4.google.com\",\n",
      "    \"ns1.google.com\",\n",
      "    \"ns3.google.com\",\n",
      "    \"ns2.google.com\"\n",
      "  ],\n",
      "  \"status\": [\n",
      "    \"clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\",\n",
      "    \"clientTransferProhibited https://icann.org/epp#clientTransferProhibited\",\n",
      "    \"clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited\",\n",
      "    \"serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited\",\n",
      "    \"serverTransferProhibited https://icann.org/epp#serverTransferProhibited\",\n",
      "    \"serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited\",\n",
      "    \"clientUpdateProhibited (https://www.icann.org/epp#clientUpdateProhibited)\",\n",
      "    \"clientTransferProhibited (https://www.icann.org/epp#clientTransferProhibited)\",\n",
      "    \"clientDeleteProhibited (https://www.icann.org/epp#clientDeleteProhibited)\",\n",
      "    \"serverUpdateProhibited (https://www.icann.org/epp#serverUpdateProhibited)\",\n",
      "    \"serverTransferProhibited (https://www.icann.org/epp#serverTransferProhibited)\",\n",
      "    \"serverDeleteProhibited (https://www.icann.org/epp#serverDeleteProhibited)\"\n",
      "  ],\n",
      "  \"emails\": [\n",
      "    \"abusecomplaints@markmonitor.com\",\n",
      "    \"whoisrequest@markmonitor.com\"\n",
      "  ],\n",
      "  \"dnssec\": \"unsigned\",\n",
      "  \"name\": null,\n",
      "  \"org\": \"Google LLC\",\n",
      "  \"address\": null,\n",
      "  \"city\": null,\n",
      "  \"state\": \"CA\",\n",
      "  \"zipcode\": null,\n",
      "  \"country\": \"US\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(whois.whois('appspot.com'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"domain_name\": [\n",
      "    \"ENGINE3D.COM\",\n",
      "    \"engine3d.com\"\n",
      "  ],\n",
      "  \"registrar\": \"Alibaba Cloud Computing (Beijing) Co., Ltd.\",\n",
      "  \"whois_server\": \"grs-whois.hichina.com\",\n",
      "  \"referral_url\": null,\n",
      "  \"updated_date\": \"2019-04-01 02:15:58\",\n",
      "  \"creation_date\": \"2017-04-17 08:39:26\",\n",
      "  \"expiration_date\": \"2020-04-17 08:39:26\",\n",
      "  \"name_servers\": [\n",
      "    \"DNS29.HICHINA.COM\",\n",
      "    \"DNS30.HICHINA.COM\"\n",
      "  ],\n",
      "  \"status\": \"ok https://icann.org/epp#ok\",\n",
      "  \"emails\": \"DomainAbuse@service.aliyun.com\",\n",
      "  \"dnssec\": \"unsigned\",\n",
      "  \"name\": null,\n",
      "  \"org\": null,\n",
      "  \"address\": null,\n",
      "  \"city\": null,\n",
      "  \"state\": \"jiang su\",\n",
      "  \"zipcode\": null,\n",
      "  \"country\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(whois.whois('engine3d.com'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 第一个网络爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 download(url)函数的各阶版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. 最简单的写法：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def download(url):\n",
    "    return urllib.request.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.workflowy.com'\n",
    "type(download(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2. 会捕获异常，写出异常原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import urllib\n",
    "\n",
    "def download(url):\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except urllib.error.URLError as e :\n",
    "        print('Download error: ', e.reason)\n",
    "        html = None\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download error: [Errno 60] Operation timed out\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.taobao2.com'\n",
    "download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于状态码：[RFC 7231 - Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content](https://tools.ietf.org/html/rfc7231#section-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3. 会重试下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, num_retries=2):\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download error: ', e.reason)\n",
    "        html = None\n",
    "        if num_retries>0:\n",
    "            if hasattr(e, 'code') and 500<=e.code<=600:\n",
    "                return download(url, num_retries-1)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function hasattr in module builtins:\n",
      "\n",
      "hasattr(obj, name, /)\n",
      "    Return whether the object has an attribute with the given name.\n",
      "    \n",
      "    This is done by calling getattr(obj, name) and catching AttributeError.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hasattr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Error:  Internal Server Error\n",
      "Download Error:  Internal Server Error\n",
      "Download Error:  Internal Server Error\n",
      "Download Error:  Internal Server Error\n"
     ]
    }
   ],
   "source": [
    "url = 'http://httpstat.us/500'\n",
    "download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4. 设置用户代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.meetup.com'\n",
    "type(download(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    print('Downloading: ', url)\n",
    "    headers = {'User-agent':user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download Error: ', e.reason)\n",
    "        html = None\n",
    "        if num_retries>0:\n",
    "            if hasattr(e, 'code') and 500<=code<600:\n",
    "                return download(url, user_agent, num_retries-1)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def download(url, user_agent='wswp', num_tries=2):\n",
    "    print('Downloading: ', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download Error: ', e.reason)\n",
    "        html = None\n",
    "        if num_tries>0:\n",
    "            if hasattr(e, 'code') and 500<=e.code<600:\n",
    "                return download(url, user_agent, num_tries-1)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 第一个网络爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. 按sitemap给出的链接获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "def crawl_sitemap(url):\n",
    "    sitemap = download(url)\n",
    "    links = re.findall(r'<loc>(.*?)</loc>', sitemap)\n",
    "    for link in links:\n",
    "        html = download(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com/sitemap.xml\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-37ee87c9b5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://example.webscraping.com/sitemap.xml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcrawl_sitemap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-8d7cae53d94c>\u001b[0m in \u001b[0;36mcrawl_sitemap\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrawl_sitemap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msitemap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<loc>(.*?)</loc>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msitemap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "url = 'http://example.webscraping.com/sitemap.xml'\n",
    "crawl_sitemap(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[一劳永逸解决：TypeError: cannot use a string pattern on a bytes-like object - 不随缘的随心，能改变的随性 - CSDN博客](https://blog.csdn.net/jieli_/article/details/70166244)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加byte到string的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import re\n",
    "import urllib\n",
    "import chardet # 检测编码格式\n",
    "\n",
    "def crawl_sitemap(url):\n",
    "    sitemap = download(url)\n",
    "    encode_type = chardet.detect(sitemap)\n",
    "    sitemap = sitemap.decode(encode_type['encoding']) #进行相应解码，赋给原标识符（变量）\n",
    "    links = re.findall(r'<loc>(.*?)</loc>', sitemap)\n",
    "    for link in links:\n",
    "        html = download(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com/sitemap.xml\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Afghanistan-1\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Albania-3\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Algeria-4\n",
      "Downloading:  http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Andorra-6\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Angola-7\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Argentina-11\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Armenia-12\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Aruba-13\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Australia-14\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Austria-15\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Azerbaijan-16\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bahamas-17\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bahrain-18\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bangladesh-19\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Barbados-20\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Belarus-21\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Belgium-22\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Belize-23\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Benin-24\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bermuda-25\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bhutan-26\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bolivia-27\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bonaire-Saint-Eustatius-and-Saba-28\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bosnia-and-Herzegovina-29\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Botswana-30\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bouvet-Island-31\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Brazil-32\n",
      "Downloading:  http://example.webscraping.com/places/default/view/British-Indian-Ocean-Territory-33\n",
      "Downloading:  http://example.webscraping.com/places/default/view/British-Virgin-Islands-34\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Brunei-35\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bulgaria-36\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Burkina-Faso-37\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Burundi-38\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Cambodia-39\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Cameroon-40\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Canada-41\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Cape-Verde-42\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Cayman-Islands-43\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Central-African-Republic-44\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Chad-45\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Chile-46\n",
      "Downloading:  http://example.webscraping.com/places/default/view/China-47\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Christmas-Island-48\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Cocos-Islands-49\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Colombia-50\n",
      "Download Error:  Service Unavailable\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c22f39fc41a1>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 503: Service Unavailable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-37ee87c9b5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://example.webscraping.com/sitemap.xml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcrawl_sitemap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-65bb3119d5fc>\u001b[0m in \u001b[0;36mcrawl_sitemap\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<loc>(.*?)</loc>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msitemap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-c22f39fc41a1>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'code' is not defined"
     ]
    }
   ],
   "source": [
    "url = 'http://example.webscraping.com/sitemap.xml'\n",
    "crawl_sitemap(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一次运行：'Too many requests'\n",
    "\n",
    "第二次运行：'Service unavailable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. 按ID遍历"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Downloading:  http://example.webscraping.com/places/default/view/Bahamas-17`  \n",
    "这个URL中，Bahamas是页面别名，web服务器会忽略这个字符串，只使用ID来匹配数据库中的相关记录。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com/view/-1\n",
      "Downloading:  http://example.webscraping.com/view/-2\n",
      "Downloading:  http://example.webscraping.com/view/-3\n",
      "Downloading:  http://example.webscraping.com/view/-4\n",
      "Downloading:  http://example.webscraping.com/view/-5\n",
      "Downloading:  http://example.webscraping.com/view/-6\n",
      "Downloading:  http://example.webscraping.com/view/-7\n",
      "Downloading:  http://example.webscraping.com/view/-8\n",
      "Downloading:  http://example.webscraping.com/view/-9\n",
      "Downloading:  http://example.webscraping.com/view/-10\n",
      "Downloading:  http://example.webscraping.com/view/-11\n",
      "Downloading:  http://example.webscraping.com/view/-12\n",
      "Downloading:  http://example.webscraping.com/view/-13\n",
      "Downloading:  http://example.webscraping.com/view/-14\n",
      "Downloading:  http://example.webscraping.com/view/-15\n",
      "Downloading:  http://example.webscraping.com/view/-16\n",
      "Downloading:  http://example.webscraping.com/view/-17\n",
      "Downloading:  http://example.webscraping.com/view/-18\n",
      "Downloading:  http://example.webscraping.com/view/-19\n",
      "Downloading:  http://example.webscraping.com/view/-20\n",
      "Downloading:  http://example.webscraping.com/view/-21\n",
      "Downloading:  http://example.webscraping.com/view/-22\n",
      "Downloading:  http://example.webscraping.com/view/-23\n",
      "Downloading:  http://example.webscraping.com/view/-24\n",
      "Downloading:  http://example.webscraping.com/view/-25\n",
      "Downloading:  http://example.webscraping.com/view/-26\n",
      "Downloading:  http://example.webscraping.com/view/-27\n",
      "Downloading:  http://example.webscraping.com/view/-28\n",
      "Downloading:  http://example.webscraping.com/view/-29\n",
      "Downloading:  http://example.webscraping.com/view/-30\n",
      "Downloading:  http://example.webscraping.com/view/-31\n",
      "Downloading:  http://example.webscraping.com/view/-32\n",
      "Downloading:  http://example.webscraping.com/view/-33\n",
      "Downloading:  http://example.webscraping.com/view/-34\n",
      "Downloading:  http://example.webscraping.com/view/-35\n",
      "Downloading:  http://example.webscraping.com/view/-36\n",
      "Downloading:  http://example.webscraping.com/view/-37\n",
      "Downloading:  http://example.webscraping.com/view/-38\n",
      "Downloading:  http://example.webscraping.com/view/-39\n",
      "Downloading:  http://example.webscraping.com/view/-40\n",
      "Downloading:  http://example.webscraping.com/view/-41\n",
      "Downloading:  http://example.webscraping.com/view/-42\n",
      "Downloading:  http://example.webscraping.com/view/-43\n",
      "Downloading:  http://example.webscraping.com/view/-44\n",
      "Downloading:  http://example.webscraping.com/view/-45\n",
      "Downloading:  http://example.webscraping.com/view/-46\n",
      "Downloading:  http://example.webscraping.com/view/-47\n",
      "Download Error:  TOO MANY REQUESTS\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c22f39fc41a1>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: TOO MANY REQUESTS",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-83f5ba5f937d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://example.webscraping.com/view/-%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhtml\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c22f39fc41a1>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'code' is not defined"
     ]
    }
   ],
   "source": [
    "for page in itertools.count(1):\n",
    "    url = 'http://example.webscraping.com/view/-%d'%page\n",
    "    html = download(url)\n",
    "    if html is None:\n",
    "        break\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "连续发生多次下载错误后才退出程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com/view/-1\n",
      "Downloading:  http://example.webscraping.com/view/-2\n",
      "Downloading:  http://example.webscraping.com/view/-3\n",
      "Downloading:  http://example.webscraping.com/view/-4\n",
      "Downloading:  http://example.webscraping.com/view/-5\n",
      "Downloading:  http://example.webscraping.com/view/-6\n",
      "Downloading:  http://example.webscraping.com/view/-7\n",
      "Downloading:  http://example.webscraping.com/view/-8\n",
      "Downloading:  http://example.webscraping.com/view/-9\n",
      "Downloading:  http://example.webscraping.com/view/-10\n",
      "Downloading:  http://example.webscraping.com/view/-11\n",
      "Downloading:  http://example.webscraping.com/view/-12\n",
      "Downloading:  http://example.webscraping.com/view/-13\n",
      "Downloading:  http://example.webscraping.com/view/-14\n",
      "Downloading:  http://example.webscraping.com/view/-15\n",
      "Downloading:  http://example.webscraping.com/view/-16\n",
      "Downloading:  http://example.webscraping.com/view/-17\n",
      "Downloading:  http://example.webscraping.com/view/-18\n",
      "Downloading:  http://example.webscraping.com/view/-19\n",
      "Downloading:  http://example.webscraping.com/view/-20\n",
      "Downloading:  http://example.webscraping.com/view/-21\n",
      "Downloading:  http://example.webscraping.com/view/-22\n",
      "Downloading:  http://example.webscraping.com/view/-23\n",
      "Downloading:  http://example.webscraping.com/view/-24\n",
      "Downloading:  http://example.webscraping.com/view/-25\n",
      "Downloading:  http://example.webscraping.com/view/-26\n",
      "Downloading:  http://example.webscraping.com/view/-27\n",
      "Downloading:  http://example.webscraping.com/view/-28\n",
      "Downloading:  http://example.webscraping.com/view/-29\n",
      "Downloading:  http://example.webscraping.com/view/-30\n",
      "Downloading:  http://example.webscraping.com/view/-31\n",
      "Downloading:  http://example.webscraping.com/view/-32\n",
      "Downloading:  http://example.webscraping.com/view/-33\n",
      "Downloading:  http://example.webscraping.com/view/-34\n",
      "Downloading:  http://example.webscraping.com/view/-35\n",
      "Downloading:  http://example.webscraping.com/view/-36\n",
      "Downloading:  http://example.webscraping.com/view/-37\n",
      "Downloading:  http://example.webscraping.com/view/-38\n",
      "Downloading:  http://example.webscraping.com/view/-39\n",
      "Downloading:  http://example.webscraping.com/view/-40\n",
      "Downloading:  http://example.webscraping.com/view/-41\n",
      "Downloading:  http://example.webscraping.com/view/-42\n",
      "Downloading:  http://example.webscraping.com/view/-43\n",
      "Downloading:  http://example.webscraping.com/view/-44\n",
      "Downloading:  http://example.webscraping.com/view/-45\n",
      "Downloading:  http://example.webscraping.com/view/-46\n",
      "Downloading:  http://example.webscraping.com/view/-47\n",
      "Downloading:  http://example.webscraping.com/view/-48\n",
      "Downloading:  http://example.webscraping.com/view/-49\n",
      "Downloading:  http://example.webscraping.com/view/-50\n",
      "Downloading:  http://example.webscraping.com/view/-51\n",
      "Downloading:  http://example.webscraping.com/view/-52\n",
      "Downloading:  http://example.webscraping.com/view/-53\n",
      "Downloading:  http://example.webscraping.com/view/-54\n",
      "Downloading:  http://example.webscraping.com/view/-55\n",
      "Downloading:  http://example.webscraping.com/view/-56\n",
      "Downloading:  http://example.webscraping.com/view/-57\n",
      "Downloading:  http://example.webscraping.com/view/-58\n",
      "Downloading:  http://example.webscraping.com/view/-59\n",
      "Downloading:  http://example.webscraping.com/view/-60\n",
      "Downloading:  http://example.webscraping.com/view/-61\n",
      "Downloading:  http://example.webscraping.com/view/-62\n",
      "Downloading:  http://example.webscraping.com/view/-63\n",
      "Downloading:  http://example.webscraping.com/view/-64\n",
      "Downloading:  http://example.webscraping.com/view/-65\n",
      "Downloading:  http://example.webscraping.com/view/-66\n",
      "Downloading:  http://example.webscraping.com/view/-67\n",
      "Downloading:  http://example.webscraping.com/view/-68\n",
      "Downloading:  http://example.webscraping.com/view/-69\n",
      "Downloading:  http://example.webscraping.com/view/-70\n",
      "Downloading:  http://example.webscraping.com/view/-71\n",
      "Downloading:  http://example.webscraping.com/view/-72\n",
      "Downloading:  http://example.webscraping.com/view/-73\n",
      "Downloading:  http://example.webscraping.com/view/-74\n",
      "Downloading:  http://example.webscraping.com/view/-75\n",
      "Downloading:  http://example.webscraping.com/view/-76\n",
      "Downloading:  http://example.webscraping.com/view/-77\n",
      "Downloading:  http://example.webscraping.com/view/-78\n",
      "Downloading:  http://example.webscraping.com/view/-79\n",
      "Downloading:  http://example.webscraping.com/view/-80\n",
      "Downloading:  http://example.webscraping.com/view/-81\n",
      "Download Error:  TOO MANY REQUESTS\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c22f39fc41a1>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: TOO MANY REQUESTS",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-faffa0cbde88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://example.webscraping.com/view/-%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhtml\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnum_errors\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c22f39fc41a1>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'code' is not defined"
     ]
    }
   ],
   "source": [
    "max_errors = 5\n",
    "num_errors = 0\n",
    "for page in itertools.count(1):\n",
    "    url = 'http://example.webscraping.com/view/-%d'%page\n",
    "    html = download(url)\n",
    "    if html is None:\n",
    "        num_errors += 1\n",
    "        if num_errors == max_errors:\n",
    "            break\n",
    "        else:\n",
    "            num_errors = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3. 链接爬虫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import chardet\n",
    "\n",
    "def link_crawler(seed_url, link_regex):\n",
    "    crawl_queue = [seed_url]\n",
    "    seen = set(crawl_queue)\n",
    "    while crawl_queue:\n",
    "        url = crawl_queue.pop()\n",
    "        html = download(url)\n",
    "        encode_type = chardet.detect(html)\n",
    "        html = html.decode(encode_type['encoding'])\n",
    "        for link in get_link(html):\n",
    "            if re.match(link_regex, link):\n",
    "                link = urllib.parse.urljoin(seed_url,link)\n",
    "                if link not in seen:\n",
    "                    seen.add(link)\n",
    "                    crawl_queue.append(link)\n",
    "def get_link(html):\n",
    "    webpage_regex = re.compile('<a[^>]+href=[\"\\'](.*?)[\"\\']', re.IGNORECASE)  \n",
    "    return webpage_regex.findall(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python2中的urlparse，在python3中变成了urllib.parse，无须单独导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method_descriptor:\n",
      "\n",
      "pop(self, index=-1, /)\n",
      "    Remove and return item at index (default last).\n",
      "    \n",
      "    Raises IndexError if list is empty or index is out of range.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(list.pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function match in module re:\n",
      "\n",
      "match(pattern, string, flags=0)\n",
      "    Try to apply the pattern at the start of the string, returning\n",
      "    a Match object, or None if no match was found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(re.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com\n"
     ]
    }
   ],
   "source": [
    "link_crawler('http://example.webscraping.com', '/(index|view)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com\n"
     ]
    }
   ],
   "source": [
    "seed_url = 'http://example.webscraping.com'\n",
    "crawl_queue = [seed_url]\n",
    "seen = set(crawl_queue)\n",
    "html = download(seed_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<a href=\"/places/default/index\"',\n",
       " '<a class=\"dropdown-toggle\" data-toggle=\"dropdown\" href=\"#\"',\n",
       " '<a href=\"/places/default/user/register?_next=/places/default/index\"',\n",
       " '<a href=\"/places/default/user/login?_next=/places/default/index\"',\n",
       " '<a href=\"/places/default/index\"',\n",
       " '<a href=\"/places/default/search\"',\n",
       " '<a href=\"/places/default/view/Afghanistan-1\"',\n",
       " '<a href=\"/places/default/view/Aland-Islands-2\"',\n",
       " '<a href=\"/places/default/view/Albania-3\"',\n",
       " '<a href=\"/places/default/view/Algeria-4\"',\n",
       " '<a href=\"/places/default/view/American-Samoa-5\"',\n",
       " '<a href=\"/places/default/view/Andorra-6\"',\n",
       " '<a href=\"/places/default/view/Angola-7\"',\n",
       " '<a href=\"/places/default/view/Anguilla-8\"',\n",
       " '<a href=\"/places/default/view/Antarctica-9\"',\n",
       " '<a href=\"/places/default/view/Antigua-and-Barbuda-10\"',\n",
       " '<a href=\"/places/default/index/1\"']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_link(html):\n",
    "    webpage_regex = re.compile('<a[^>]+href=[\"\\'].*?[\"\\']', re.IGNORECASE) \n",
    "    #webpage_regex = re.compile('<a[^>]+href=[\"\\'](.*?)[\"\\']', re.IGNORECASE) \n",
    "    return webpage_regex.findall(html)\n",
    "get_link(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始html字符串是：`<a href=\"/places/default/view/Afghanistan-1\"><img src=\"/places/static/images/flags/af.png\"> Afghanistan</a>`\n",
    "\n",
    "webpage_regex是：`<a[^>]+href=[\"\\'](.*?)[\"\\']`\n",
    "\n",
    "为什么会匹配结果为:`/places/default/view/Afghanistan-1`？？秘密在于括号，有了括号，就是有分组。findall的返回值就是元组组成的列表。因为只有一个分组，所以就是只有`(.*?)`部分的内容。  \n",
    "\n",
    "经过测试，拿掉了括号，果然结果是`<a href=\"/places/default/index\"'`这种了，居然还有个a class的结果：`<a class=\"dropdown-toggle\" data-toggle=\"dropdown\" href=\"#\"'`，瞬间明白了为什么表达式是`a[^>]+`，为了有的语句会在这中间插入class。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in get_link(html):\n",
    "    link_regex = '/(index|view)'\n",
    "    if re.match(link_regex, link):\n",
    "        link = urllib.parse.urljoin(seed_url,link)\n",
    "        if link not in seen:\n",
    "            seen.add(link)\n",
    "            crawl_queue.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in get_link(html):\n",
    "    link_regex = '/(index|view)'\n",
    "    if re.compile(link_regex).search(link):\n",
    "        link = urllib.parse.urljoin(seed_url,link)\n",
    "        if link not in seen:\n",
    "            seen.add(link)\n",
    "            crawl_queue.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(link_regex, '/places/default/view/Antigua-and-Barbuda-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/view'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmlRegex = re.compile(link_regex)\n",
    "mo = htmlRegex.search('/places/default/view/Antigua-and-Barbuda-10')\n",
    "mo.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match('/w+', '/places/default/view/Antigua-and-Barbuda-10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在python3中，re.match()必须要在起始位置匹配成功才行。python2似乎没有这样的规定。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(15, 20), match='/view'>\n"
     ]
    }
   ],
   "source": [
    "mo = re.compile(link_regex).search('/places/default/view/Antigua-and-Barbuda-10')\n",
    "print(mo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面的研究，必须要把原程序中的match方法改成search方法才行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com\n",
      "Downloading:  http://example.webscraping.com/places/default/index/1\n",
      "Downloading:  http://example.webscraping.com/places/default/index/2\n",
      "Downloading:  http://example.webscraping.com/places/default/index/3\n",
      "Downloading:  http://example.webscraping.com/places/default/index/4\n",
      "Downloading:  http://example.webscraping.com/places/default/index/5\n",
      "Downloading:  http://example.webscraping.com/places/default/index/6\n",
      "Downloading:  http://example.webscraping.com/places/default/index/7\n",
      "Downloading:  http://example.webscraping.com/places/default/index/8\n",
      "Downloading:  http://example.webscraping.com/places/default/index/9\n",
      "Downloading:  http://example.webscraping.com/places/default/index/10\n",
      "Downloading:  http://example.webscraping.com/places/default/index/11\n",
      "Downloading:  http://example.webscraping.com/places/default/index/12\n",
      "Downloading:  http://example.webscraping.com/places/default/index/13\n",
      "Downloading:  http://example.webscraping.com/places/default/index/14\n",
      "Downloading:  http://example.webscraping.com/places/default/index/15\n",
      "Downloading:  http://example.webscraping.com/places/default/index/16\n",
      "Downloading:  http://example.webscraping.com/places/default/index/17\n",
      "Downloading:  http://example.webscraping.com/places/default/index/18\n",
      "Download Error:  TOO MANY REQUESTS\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-08b504c8765a>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: TOO MANY REQUESTS",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-08b504c8765a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#增加default，减少获取量。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mlink_crawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://example.webscraping.com'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default/(index|view)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-08b504c8765a>\u001b[0m in \u001b[0;36mlink_crawler\u001b[0;34m(seed_url, link_regex)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcrawl_queue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrawl_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-08b504c8765a>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mencode_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'code' is not defined"
     ]
    }
   ],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import urllib\n",
    "import re\n",
    "import chardet\n",
    "\n",
    "def link_crawler(seed_url, link_regex):\n",
    "    crawl_queue = [seed_url]\n",
    "    seen = set(crawl_queue)\n",
    "    while crawl_queue:\n",
    "        url = crawl_queue.pop()\n",
    "        html = download(url)\n",
    "        for link in get_link(html):\n",
    "            if re.compile(link_regex).search(link):\n",
    "                link = urllib.parse.urljoin(seed_url,link)\n",
    "                if link not in seen:\n",
    "                    seen.add(link)\n",
    "                    crawl_queue.append(link)\n",
    "\n",
    "def get_link(html):\n",
    "    webpage_regex = re.compile('<a[^>]+href=[\"\\'](.*?)[\"\\']', re.IGNORECASE)  \n",
    "    return webpage_regex.findall(html)\n",
    "\n",
    "def download(url, user_agent='wswp', num_retries=2):\n",
    "    # 原先的输出为二进制，非string。把转string的代码放到这里，改为输出string。\n",
    "    print('Downloading: ', url)\n",
    "    headers = {'User-agent':user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download Error: ', e.reason)\n",
    "        html = None\n",
    "        if num_retries>0:\n",
    "            if hasattr(e, 'code') and 500<=code<600:\n",
    "                return download(url, user_agent, num_retries-1)\n",
    "    encode_type = chardet.detect(html)\n",
    "    html = html.decode(encode_type['encoding'])\n",
    "    return html\n",
    "\n",
    "#增加default，减少获取量。\n",
    "link_crawler('http://example.webscraping.com', 'default/(index|view)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 4, 5, 6, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "s = set([6,2,8,4,2,6,7,5,5])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python3 集合类型 | Python 3 教程 - 与知](https://www.yuzhi100.com/tutorial/python3/python3-sets)\n",
    "\n",
    "set（集合）类型是Python3的一种数据类型，集合（set）中包含的元素是无序的，无重复的序列。集合数据类型的主要作用是**测试是否是集合成员中的一个**，和**消除重复元素**。\n",
    "\n",
    "集合（set）是可变数据类型，支持插入和删除元素，但是不支持索引和分片元素。  \n",
    "\n",
    "测试是否是集合中的一个，以及消除重复元素，怪不得seen要用set类型，意思是只要看过的，一概不爬，不管这一路上碰到多少次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.engine3d.com'\n",
    "user_agent='wswp'\n",
    "\n",
    "headers = {'User-agent':user_agent}\n",
    "request = urllib.request.Request(url, headers=headers)\n",
    "html = urllib.request.urlopen(request).read()\n",
    "encode_type = chardet.detect(html)\n",
    "html = html.decode(encode_type['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-agent': 'wswp'}\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "print(encode_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urllib.request.Request object at 0x10f474668>\n"
     ]
    }
   ],
   "source": [
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <title>三维GIS软件与服务开发商_三维GIS行业解决方案提供商_中科图新</title>\n",
      "    <meta name=\"description\" content=\"苏州中科图新网络科技有限公司是国内优秀的三维GIS软件与服务提供商，在三维GIS行业深耕近10年。公司专注于倾斜摄影实景三维应用，以技术创新为核心竞争力，已有4项发明专利和20多项软件著作权。中科图新拥有Wish3D和LocaSpace 两大产品系，致力于为企业用户和开发者提供更轻便实用的三维地图软件及数据发布服务，已经成功地应用于无人机航测、规划设计、水利、社区管理、智慧城市等多个领域 ，获得众多用户的认可。\" />\n",
      "    <meta name=\"keywords\" content=\"locaspace、LSV、Wish3D、GIS、三维实景、解决方案、定制开发、OEM\" />\n",
      "    <link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"assets/img/wish3d.ico?20170313\" media=\"screen\">\n",
      "    <meta content='width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0' name='viewport'>\n",
      "    <link rel=\"stylesheet\" href=\"assets/css/font-awesome-4.7.0/css/font-awesome.css\">\n",
      "    <link rel=\"stylesheet\" href=\"assets/css/bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"assets/css/material-kit-1.css?v=1.3.0\">\n",
      "    <link rel=\"stylesheet\" href=\"assets/css/css.css\">\n",
      "    <link rel=\"stylesheet\" href=\"assets/css/engine3d.css\">\n",
      "    <style>\n",
      "        body {\n",
      "            font-weight: 400;\n",
      "            font-style: normal;\n",
      "            font-size: 18px;\n",
      "            color: #fff;\n",
      "            font-family: 'NotoSansCJKsc-Regular', 'Noto Sans CJK SC', 'Microsoft YaHei', 'SimSun';\n",
      "        }\n",
      "\n",
      "        .text-content {\n",
      "            font-weight: 400;\n",
      "            font-style: normal;\n",
      "            font-size: 14px;\n",
      "            color: #000;\n",
      "            font-family: 'NotoSansCJKsc-Regular', 'Noto Sans CJK SC', 'Microsoft YaHei', 'SimSun';\n",
      "        }\n",
      "\n",
      "        h5 {\n",
      "            color: #000;\n",
      "        }\n",
      "\n",
      "        body {\n",
      "            background-color: #fff;\n",
      "        }\n",
      "\n",
      "        .carousel-caption {\n",
      "            margin-top: 100px;\n",
      "        }\n",
      "\n",
      "        .header-filter > .container {\n",
      "            height: 45vh;\n",
      "        }\n",
      "\n",
      "        .header-filter:before, .header-filter:after {\n",
      "            position: absolute;\n",
      "            z-index: 1;\n",
      "            width: 0%;\n",
      "            height: 0%;\n",
      "            display: block;\n",
      "            left: 0;\n",
      "            top: 0;\n",
      "            content: \"\";\n",
      "        }\n",
      "\n",
      "        .features-1 {\n",
      "            padding: 30px 0;\n",
      "        }\n",
      "\n",
      "        .footer {\n",
      "            background: #fff;\n",
      "        }\n",
      "    </style>\n",
      "    <script>\n",
      "        var _hmt = _hmt || [];\n",
      "    </script>\n",
      "    <script src=\"assets/js/baidustatistics.js\"></script>\n",
      "</head>\n",
      "\n",
      "<body class=\"pricing\">\n",
      "<nav class=\"navbar navbar-primary navbar-transparent navbar-fixed-top navbar-color-on-scroll\">\n",
      "    <div class=\"container\">\n",
      "        <!-- Brand and toggle get grouped for better mobile display -->\n",
      "        <div class=\"navbar-header\">\n",
      "            <a class=\"navbar-brand\" href=\"index.html\"><img alt=\"中科图新LOGO\" src=\"assets/img/index-top.png\" /></a>\n",
      "            <button type=\"button\" class=\"navbar-toggle\" data-toggle=\"collapse\" data-target=\"#navigation-example\">\n",
      "                <span class=\"sr-only\">Toggle navigation</span>\n",
      "                <span class=\"icon-bar\"></span>\n",
      "                <span class=\"icon-bar\"></span>\n",
      "                <span class=\"icon-bar\"></span>\n",
      "            </button>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"collapse navbar-collapse\">\n",
      "            <ul class=\"nav navbar-nav navbar-left head-font\">\n",
      "                \t\t\t  \t\t\t <li class=\"dropdown\">\n",
      "<a href=\"javascript:void(0);\" class=\"dropdown-toggle\" data-toggle=\"dropdown\">      公司简介 <b class=\"caret\"></b> </a>\n",
      "\t\t\t <ul class=\"dropdown-menu dropdown-with-icons\" >\n",
      "\t\t\t   \t\t\t             <li>\n",
      "                            <a href=\"about.html\" >\n",
      "                                 公司简介\n",
      "                            </a>\n",
      "                        </li>\n",
      "\t\t\t   \t\t\t             <li>\n",
      "                            <a href=\"purpose.html\" >\n",
      "                                 核心价值观\n",
      "                            </a>\n",
      "                        </li>\n",
      "\t\t\t   \t\t\t             <li>\n",
      "                            <a href=\"develop.html\" >\n",
      "                                 发展历程\n",
      "                            </a>\n",
      "                        </li>\n",
      "\t\t\t   \t\t\t             <li>\n",
      "                            <a href=\"mainmember.html\" >\n",
      "                                 主要成员\n",
      "                            </a>\n",
      "                        </li>\n",
      "\t\t\t   \t\t\t             <li>\n",
      "                            <a href=\"office.html\" >\n",
      "                                 办公环境\n",
      "                            </a>\n",
      "                        </li>\n",
      "\t\t\t   \t\t\t             <li>\n",
      "                            <a href=\"certificate.html\" >\n",
      "                                 荣誉资质\n",
      "                            </a>\n",
      "                        </li>\n",
      "\t\t\t   \t\t\t   </ul>\n",
      "\t\t\t   </li>\n",
      "\t\t\t   \t\t\t\t\t\t  \t\t\t    <li>\n",
      "\t  \t\t   <a href=\"businessstruct.html\">\n",
      "\t\t\t       产品与服务\n",
      "\t\t\t   </a>\n",
      "\t\t\t   </li>\n",
      "\t\t\t   \t\t\t\t\t\t  \t\t\t    <li>\n",
      "\t  \t\t   <a href=\"solution.html\">\n",
      "\t\t\t       解决方案\n",
      "\t\t\t   </a>\n",
      "\t\t\t   </li>\n",
      "\t\t\t   \t\t\t\t\t\t  \t\t\t    <li>\n",
      "\t  \t\t   <a href=\"http://news.engine3d.com/\">\n",
      "\t\t\t       资讯动态\n",
      "\t\t\t   </a>\n",
      "\t\t\t   </li>\n",
      "\t\t\t   \t\t\t\t\t\t  \t\t\t    <li>\n",
      "\t  \t\t   <a href=\"jobneed.html\">\n",
      "\t\t\t       招贤纳士\n",
      "\t\t\t   </a>\n",
      "\t\t\t   </li>\n",
      "\t\t\t   \t\t\t\t\t\t  \t\t\t    <li>\n",
      "\t  \t\t   <a href=\"contactus.html\">\n",
      "\t\t\t       联系我们\n",
      "\t\t\t   </a>\n",
      "\t\t\t   </li>\n",
      "\t\t\t   \t\t\t\t\t\t  \t\t\t <li class=\"dropdown\">\n",
      "<a href=\"javascript:void(0);\" class=\"dropdown-toggle\" data-toggle=\"dropdown\">      建模培训 <b class=\"caret\"></b> </a>\n",
      "\t\t\t <ul class=\"dropdown-menu dropdown-with-icons\" >\n",
      "\t\t\t   \t\t\t             <li>\n",
      "                            <a href=\"course.html\" >\n",
      "                                 ContextCapture(Smart3D)\n",
      "                            </a>\n",
      "                        </li>\n",
      "\t\t\t   \t\t\t             <li>\n",
      "                            <a href=\"pix4d.html\" >\n",
      "                                 Pix4D\n",
      "                            </a>\n",
      "                        </li>\n",
      "\t\t\t   \t\t\t   </ul>\n",
      "\t\t\t   </li>\n",
      "\t\t\t   \t\t\t            </ul>\n",
      "            <ul class=\"nav navbar-nav navbar-right head-font\">\n",
      "                <li >\n",
      "                    <a href=\"#\">\n",
      "                        <img alt=\"中科图新客服电话\" src=\"assets/img/head-photo.svg\" style=\"margin-top: -6px;\"/>&nbsp;\n",
      "                        400-867-5155(工作日 9:00~17:30)\n",
      "                    </a>\n",
      "                </li>\n",
      "\n",
      "            </ul>\n",
      "        </div>\n",
      "    </div>\n",
      "</nav>\n",
      "<div id=\"carousel-example-generic\" class=\"carousel slide\" data-ride=\"carousel\">\n",
      "    <div class=\"carousel slide\" data-ride=\"carousel\">\n",
      "\n",
      "        <!-- Indicators -->\n",
      "        <ol class=\"carousel-indicators\">\n",
      "            <li data-target=\"#carousel-example-generic\" data-slide-to=\"0\" class=\"active\"></li>\n",
      "            <li data-target=\"#carousel-example-generic\" data-slide-to=\"1\" class=\"\"></li>\n",
      "            <li data-target=\"#carousel-example-generic\" data-slide-to=\"2\" class=\"\"></li>\n",
      "        </ol>\n",
      "\n",
      "        <!-- Wrapper for slides -->\n",
      "        <div class=\"carousel-inner\">\n",
      "            <div class=\"item  active\">\n",
      "                <a href=\"pix4d.html\">\n",
      "                    <div class=\"page-header header-filter\"\n",
      "                            style=\"background-image: url('assets/img/course/index-backgroud.png'); height: 65vh\">\n",
      "\n",
      "                        <div class=\"container\">\n",
      "                            <div class=\"row\">\n",
      "                                <div class=\"carousel-caption\">\n",
      "                                </div>\n",
      "                            </div>\n",
      "                        </div>\n",
      "                    </div>\n",
      "                </a>\n",
      "            </div>\n",
      "\n",
      "            <div class=\"item \">\n",
      "                <a href=\"http://www.wish3d.com/\">\n",
      "                    <div class=\"page-header header-filter\"\n",
      "                         style=\"background-image: url('assets/img/index-backgroud2.jpg'); height: 65vh\">\n",
      "\n",
      "                        <div class=\"container\">\n",
      "                            <div class=\"row\">\n",
      "                                <div class=\"carousel-caption\">\n",
      "                                </div>\n",
      "                            </div>\n",
      "                        </div>\n",
      "                    </div>\n",
      "                </a>\n",
      "            </div>\n",
      "            <div class=\"item\">\n",
      "\n",
      "                <a href=\"http://www.locaspace.cn\">\n",
      "                    <div class=\"page-header header-filter\"\n",
      "                         style=\"background-image: url('assets/img/index-backgroud3.jpg');height: 65vh\">\n",
      "                        <div class=\"container\">\n",
      "                            <div class=\"row\">\n",
      "                                <div class=\"carousel-caption\">\n",
      "                                </div>\n",
      "                            </div>\n",
      "                        </div>\n",
      "\n",
      "                    </div>\n",
      "                </a>\n",
      "            </div>\n",
      "            \n",
      "            <!-- <div class=\"item active left\">\n",
      "                 <a href=\"http://www.wish3d.com/Activity/1111.html\">\n",
      "                 <div class=\"page-header header-filter\" style=\"background-image: url('assets/img/index-backgroud2.jpg');height: 65vh\">\n",
      "\n",
      "                     <div class=\"container\">\n",
      "                         <div class=\"row\">\n",
      "                             <div class=\"carousel-caption\" >\n",
      "                             </div>\n",
      "                         </div>\n",
      "                     </div>\n",
      "\n",
      "                 </div></a>\n",
      "\n",
      "             </div>-->\n",
      "\n",
      "        </div>\n",
      "\n",
      "        <!-- Controls -->\n",
      "        <a class=\"left carousel-control\" href=\"#carousel-example-generic\" data-slide=\"prev\">\n",
      "            <i class=\"material-icons\">keyboard_arrow_left</i>\n",
      "        </a>\n",
      "        <a class=\"right carousel-control\" href=\"#carousel-example-generic\" data-slide=\"next\">\n",
      "            <i class=\"material-icons\">keyboard_arrow_right</i>\n",
      "        </a>\n",
      "    </div>\n",
      "</div>\n",
      "\n",
      "<div class=\"container\">\n",
      "    <div class=\"features-1\" style=\"text-align: left;\">\n",
      "        <div class=\"row\">\n",
      "            <div class=\"col-md-4\">\n",
      "                <h5>中科图新简介</h5><span class=\"text-content\">\n",
      "             <a href=\"about.html\">  <P class=\"card-description text-content14\">  苏州中科图新网络科技有限公司是国内优秀的三维GIS软件与服务提供商，在三维GIS行业深耕近10年。公司坚持专注、务实、开放、创新的核心价值观，专注于倾斜摄影实景三维应用，以技术创新为核心竞争力，已有4项发明专利和20多项软件著作权。我们拥有Wish3D和LocaSpace 两大产品系，致力于为企业\n",
      "           </P></a></span>\n",
      "            </div>\n",
      "            <div class=\"col-md-4\">\n",
      "                <h5>核心价值观</h5>\n",
      "                <a href=\"purpose.html\">\n",
      "                    <P class=\"card-description text-content14\">专注:图新创始团队深耕三维地图引擎10多年，始终围...</p>\n",
      "                    <P class=\"card-description text-content14\">务实:在研发产品或提供服务时，团队立足于用户痛点....</p>\n",
      "                    <P class=\"card-description text-content14\">开放:秉持开放的理念，携手行业伙伴，互补长短，为无....</p>\n",
      "                    <P class=\"card-description text-content14\">创新:以技术创新为核心竞争力，已经拥有4项发明专利....\n",
      "                    </p></a>\n",
      "            </div>\n",
      "            <div class=\"col-md-4\">\n",
      "                <h5><a href=\"http://news.engine3d.com/\" style=\"color: #000\">新闻资讯</a></h5>\n",
      "                <ul class=\"index-link\" style=\"    margin-left: -36px;\">\n",
      "                    <li>\n",
      "                        <a href=\"http://news.engine3d.com/newdetail-1.html\" class=\"card-description text-content14\">\n",
      "                            北京交通大学师生到我司参观交流\n",
      "                        </a>\n",
      "                        <div class=\"text-content14\" style=\"float: right\">2018/08/10</div>\n",
      "                    </li>\n",
      "                    <li>\n",
      "                        <a href=\"http://news.engine3d.com/newdetail-2.html\" class=\"text-content14\">\n",
      "                            中科图新年会圆满举办！\n",
      "                        </a>\n",
      "                        <div class=\"text-content14\" style=\"float: right\">2018/02/03</div>\n",
      "                    </li>\n",
      "                    <li>\n",
      "                        <a href=\"http://news.engine3d.com/newdetail-3.html\" class=\"text-content14\">\n",
      "                            今年最后一次三维建模高级班结束\n",
      "                        </a>\n",
      "                        <div class=\"text-content14\" style=\"float: right\">2017/12/28</div>\n",
      "                    </li>\n",
      "                    <li>\n",
      "                        <a href=\"http://news.engine3d.com/newdetail-4.html\" class=\"text-content14\">\n",
      "                            图新精诚学院第一期SDK培训结束\n",
      "                        </a>\n",
      "                        <div class=\"text-content14\" style=\"float: right\">2017/12/20</div>\n",
      "                    </li>\n",
      "                    <li>\n",
      "                        <a href=\"http://news.engine3d.com/newdetail-5.html\" class=\"text-content14\">\n",
      "                            常州市委督查组调研我司\n",
      "                        </a>\n",
      "                        <div class=\"text-content14\" style=\"float: right\">2017/11/16</div>\n",
      "                    </li>\n",
      "                </ul>\n",
      "            </div>\n",
      "\n",
      "        </div>\n",
      "    </div>\n",
      "    <hr>\n",
      "</div>\n",
      "<footer class=\"footer footer-white footer-big\">\n",
      "    <div class=\"container\">\n",
      "\n",
      "        <div class=\"content text-content14\">\n",
      "            <div class=\"row\">\n",
      "                <div class=\"col-md-1 col-xs-0\">\n",
      "                </div>\n",
      "                <div class=\"col-md-2 col-xs-4\">\n",
      "                    <h5>关于我们</h5>\n",
      "                    <ul class=\"links-vertical\">\n",
      "                        <li>\n",
      "                            <a href=\"about.html\">\n",
      "                                关于我们\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"purpose.html\">\n",
      "                                核心价值观\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"develop.html\">\n",
      "                                发展历程\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"mainmember.html\">\n",
      "                                管理团队\n",
      "                            </a>\n",
      "                        </li>\n",
      "                    </ul>\n",
      "                </div>\n",
      "                <div class=\"col-md-2 col-xs-4\">\n",
      "                    <h5>业务体系</h5>\n",
      "                    <ul class=\"links-vertical\">\n",
      "                        <li>\n",
      "                            <a href=\"businessstruct.html\">\n",
      "                                软件产品\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"businessstruct.html\">\n",
      "                                定制服务\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"businessstruct.html\">\n",
      "                                商务合作\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"businessstruct.html\">\n",
      "                                精诚合作\n",
      "                            </a>\n",
      "                        </li>\n",
      "                    </ul>\n",
      "                </div>\n",
      "                <div class=\"col-md-2 col-xs-4\">\n",
      "                    <h5>资讯动态</h5>\n",
      "                    <ul class=\"links-vertical\">\n",
      "                        <li>\n",
      "                            <a href=\"http://news.engine3d.com/\">\n",
      "                                公司动态\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"http://news.engine3d.com/\">\n",
      "                                媒体报道\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"http://news.engine3d.com/\">\n",
      "                                行业案例\n",
      "                            </a>\n",
      "                        </li>\n",
      "                    </ul>\n",
      "                </div>\n",
      "\n",
      "                <div class=\"col-md-2 col-xs-6\">\n",
      "                    <h5>联系我们</h5>\n",
      "                    <ul class=\"links-vertical\">\n",
      "                        <li>\n",
      "                            <a href=\"contactus.html\">\n",
      "                                联系我们\n",
      "                            </a>\n",
      "                        </li>\n",
      "                        <li>\n",
      "                            <a href=\"jobneed.html\">\n",
      "                                加入我们\n",
      "                            </a>\n",
      "                        </li>\n",
      "                    </ul>\n",
      "                </div>\n",
      "                <div class=\"col-md-3 col-xs-6\">\n",
      "                    <h5>媒体账号</h5>\n",
      "                    <p>\n",
      "                        <img alt=\"Wish3D微信公众号\" src=\"assets/img/Wish3D.png\">\n",
      "                    </p>\n",
      "\n",
      "                </div>\n",
      "\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <hr>\n",
      "\n",
      "\n",
      "        <div class=\"copyright pull-center\">\n",
      "            ©2019<b>苏州中科图新网络科技有限公司</b><a href=\"http://www.miitbeian.gov.cn\">苏ICP备16002578号</a>\n",
      "        </div>\n",
      "    </div>\n",
      "</footer>\n",
      "<script src=\"assets/js/jquery.min.js\"></script>\n",
      "<script src=\"assets/js/bootstrap.min.js\"></script>\n",
      "<script src=\"assets/js/material.min.js\"></script>\n",
      "<script src=\"assets/js/moment.min.js\"></script>\n",
      "<script src=\"assets/js/nouislider.min.js\"></script>\n",
      "<script src=\"assets/js/bootstrap-datetimepicker.js\"></script>\n",
      "<script src=\"assets/js/bootstrap-selectpicker.js\"></script>\n",
      "<script src=\"assets/js/bootstrap-tagsinput.js\"></script>\n",
      "<script src=\"assets/js/jasny-bootstrap.min.js\"></script>\n",
      "<script src=\"assets/js/material-kit.js\"></script>\n",
      "<script type=\"text/javascript\"\n",
      "        src=\"assets/js/Statistics.js\"></script>\n",
      "\n",
      "</body>\n",
      "\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://www.engine3d.com\n",
      "Downloading:  http://www.miitbeian.gov.cn\n",
      "Downloading:  http://news.engine3d.com/newdetail-5.html\n",
      "Downloading:  http://www.engine3d.com/newlist.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-16.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-15.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-14.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-13.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-12.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-11.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-10.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-9.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-8.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-7.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-6.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-5.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-4.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-3.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-2.html\n",
      "Downloading:  http://www.engine3d.com/newdetail-1.html\n",
      "Downloading:  http://www.engine3d.com#medianews\n"
     ]
    },
    {
     "ename": "RemoteDisconnected",
     "evalue": "Remote end closed connection without response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-f8ccfd64d441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlink_crawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.*?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-08b504c8765a>\u001b[0m in \u001b[0;36mlink_crawler\u001b[0;34m(seed_url, link_regex)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcrawl_queue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrawl_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-08b504c8765a>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Download Error: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;31m# Presumably, the server closed the connection before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    266\u001b[0m                                      \" response\")\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response"
     ]
    }
   ],
   "source": [
    "link_crawler(url,'.*?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这两个网站的返回错误是不一样的：  \n",
    "一个是`Download Error:  TOO MANY REQUESTS`，`NameError: name 'code' is not defined`\n",
    "一个是`RemoteDisconnected   Traceback (most recent call last)`,`RemoteDisconnected: Remote end closed connection without response`。第二个没有返回e.reason。直接是失去连接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package urllib:\n",
      "\n",
      "NAME\n",
      "    urllib\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.7/library/urllib\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    error\n",
      "    parse\n",
      "    request\n",
      "    response\n",
      "    robotparser\n",
      "\n",
      "FILE\n",
      "    /Users/caimeijuan/anaconda/envs/python35/lib/python3.7/urllib/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(urllib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4. 链接爬虫的高级功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解析robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.robotparser as robotparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = robotparser.RobotFileParser()\n",
    "rp.set_url('http://example.webscraping.com/robots.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method read in module urllib.robotparser:\n",
      "\n",
      "read() method of urllib.robotparser.RobotFileParser instance\n",
      "    Reads the robots.txt URL and feeds it to the parser.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rp.read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用了robots.txt文件中封禁的代理名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://example.webscraping.com'\n",
    "user_agent = 'BadCrawler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp.can_fetch(user_agent, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改用其他名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_agent = 'GoodCrawler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp.can_fetch(user_agent, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**假如不运行rp.read()**'，则即使是GoodCrawler'这样的代理，也**无法获取**网页内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入这个功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com\n",
      "Downloading:  http://example.webscraping.com/places/default/index/1\n",
      "Downloading:  http://example.webscraping.com/places/default/index/2\n",
      "Downloading:  http://example.webscraping.com/places/default/index/3\n",
      "Downloading:  http://example.webscraping.com/places/default/index/4\n",
      "Downloading:  http://example.webscraping.com/places/default/index/5\n",
      "Downloading:  http://example.webscraping.com/places/default/index/6\n",
      "Downloading:  http://example.webscraping.com/places/default/index/7\n",
      "Downloading:  http://example.webscraping.com/places/default/index/8\n",
      "Downloading:  http://example.webscraping.com/places/default/index/9\n",
      "Downloading:  http://example.webscraping.com/places/default/index/10\n",
      "Downloading:  http://example.webscraping.com/places/default/index/11\n",
      "Download Error:  TOO MANY REQUESTS\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-bb88fb0e9f6e>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: TOO MANY REQUESTS",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-bb88fb0e9f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#增加default，减少获取量。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mlink_crawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://example.webscraping.com'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default/(index|view)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-bb88fb0e9f6e>\u001b[0m in \u001b[0;36mlink_crawler\u001b[0;34m(seed_url, link_regex)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrawl_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Blocked by robots.txt: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-bb88fb0e9f6e>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, user_agent, num_retries)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mencode_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'code' is not defined"
     ]
    }
   ],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import urllib\n",
    "import re\n",
    "import chardet\n",
    "import urllib.robotparser as robotsparser\n",
    "\n",
    "def link_crawler(seed_url, link_regex):\n",
    "    crawl_queue = [seed_url]\n",
    "    seen = set(crawl_queue)\n",
    "    rp = robotparser.RobotFileParser()\n",
    "    rp.set_url('http://example.webscraping.com/robots.txt')\n",
    "    rp.read()\n",
    "    while crawl_queue:\n",
    "        url = crawl_queue.pop()\n",
    "        if rp.can_fetch(user_agent, url):\n",
    "            html = download(url)\n",
    "        else:\n",
    "            print('Blocked by robots.txt: ', url)\n",
    "        for link in get_link(html):\n",
    "            if re.compile(link_regex).search(link):\n",
    "                link = urllib.parse.urljoin(seed_url,link)\n",
    "                if link not in seen:\n",
    "                    seen.add(link)\n",
    "                    crawl_queue.append(link)\n",
    "\n",
    "def get_link(html):\n",
    "    webpage_regex = re.compile('<a[^>]+href=[\"\\'](.*?)[\"\\']', re.IGNORECASE)  \n",
    "    return webpage_regex.findall(html)\n",
    "\n",
    "def download(url, user_agent='BadCrawler', num_retries=2):\n",
    "    # 原先的输出为二进制，非string。把转string的代码放到这里，改为输出string。\n",
    "    print('Downloading: ', url)\n",
    "    headers = {'User-agent':user_agent}\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib.request.urlopen(request).read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Download Error: ', e.reason)\n",
    "        html = None\n",
    "        if num_retries>0:\n",
    "            if hasattr(e, 'code') and 500<=code<600:\n",
    "                return download(url, user_agent, num_retries-1)\n",
    "    encode_type = chardet.detect(html)\n",
    "    html = html.decode(encode_type['encoding'])\n",
    "    return html\n",
    "\n",
    "#增加default，减少获取量。\n",
    "link_crawler('http://example.webscraping.com', 'default/(index|view)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user_agent='BadCrawler'`没有带来封禁，仍然死于too many requests.这是为什么呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 了解urllib\n",
    "\n",
    "### urllib.error\n",
    "\n",
    "- urllib.error.ContentTooShortError: Exception raised when downloaded size does not match content-length.当urlretrieve() 函数检测到下载数据量小于预期量（由Content-Length标头给出）时，会引发此异常。\n",
    "- urllib.error.HTTPError: Raised when HTTP error occurs, but also acts like non-error return. 虽然是一个异常（它的子类URLError），但 HTTPError它也可以作为一个非特殊的文件类返回值（urlopen()返回相同的东西）。这在处理异常HTTP错误（例如身份验证请求）时非常有用。\n",
    "- urllib.error.URLError: Base class for I/O related errors. 处理程序遇到问题时会引发此异常（或派生异常）。它是的子类OSError。\n",
    "- urllib.error.urllib\n",
    "\n",
    "### urllib.response\n",
    "\n",
    "- urllib.response.addbase: Base class for addinfo and addclosehook. Is a good idea for garbage collection.\n",
    "- urllib.response.addclosehook: Class to add a close hook to an open file.\n",
    "- urllib.response.addinfo: class to add an info() method to an open file.\n",
    "- urllib.response.addinfourl: class to add info() and geturl() methods to an open file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib.request: 打开和浏览url中内容 \n",
    "\n",
    "- urllib.request.url2pathname: \n",
    "OS-specific conversion from a relative URL of the 'file' scheme to a file system path; not recommended for general use.  \n",
    "\n",
    "- urllib.request.urlcleanup: \n",
    "Clean up temporary files from urlretrieve calls.  \n",
    "\n",
    "- urllib.request.urljoin： \n",
    "Join a base URL and a possibly relative URL to form an absolute interpretation of the latter.  \n",
    "\n",
    "- urllib.request.urlopen: \n",
    "Open the URL url, which can be either a string or a Request object. \n",
    "    `urlopen(url, data=None, timeout=<object object at 0x109fa9630>, *, cafile=None, capath=None, cadefault=False, context=None)`   \n",
    "\n",
    "- urllib.request.urlretrieve: \n",
    "Retrieve a URL into a temporary location on disk.\n",
    "    `urlretrieve(url, filename=None, reporthook=None, data=None)`\n",
    "\n",
    "- urllib.request.urlsplit:  \n",
    "Parse a URL into 5 components:`<scheme>://<netloc>/<path>?<query>#<fragment>`\n",
    "    `urlsplit(url, scheme='', allow_fragments=True)`\n",
    "\n",
    "- urllib.request.urlparse:  \n",
    "Parse a URL into 6 components:`<scheme>://<netloc>/<path>;<params>?<query>#<fragment>`\n",
    "    `urlparse(url, scheme='', allow_fragments=True)`  \n",
    "    \n",
    "- urllib.request.urlunparse:\n",
    "Put a parsed URL back together again.  This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had redundant delimiters, e.g. a ? with an empty query (the draft states that these are equivalent).\n",
    "\n",
    "- urllib.request.Request: \n",
    "    `Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)`\n",
    "    `type(urllib.request.Request(url)): urllib.request.Request `，可替代`urllib.request.urlopen(url)`中的url。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib.parse:解析url\n",
    "\n",
    "- urllib.parse.urldefrag: \n",
    "Removes any existing fragment from URL. Returns a tuple of the defragmented URL and the fragment.  If the URL contained no fragments, the second element is the empty string.\n",
    "\n",
    "- urllib.parse.urlencode: \n",
    "Encode a dict or sequence of two-element tuples into a URL query string.\n",
    "    `urlencode(query, doseq=False, safe='', encoding=None, errors=None, quote_via=<function quote_plus at 0x10a8c7ea0>)`  \n",
    "\n",
    "- urllib.parse.urljoin: \n",
    "Join a base URL and a possibly relative URL to form an absolute interpretation of the latter.\n",
    "    `urljoin(base, url, allow_fragments=True)`\n",
    "\n",
    "- urllib.parse.urlparse: \n",
    "Parse a URL into 6 components:` <scheme>://<netloc>/<path>;<params>?<query>#<fragment>`\n",
    "    `urlparse(url, scheme='', allow_fragments=True)`\n",
    "\n",
    "- urllib.parse.urlunparse: \n",
    "Put a parsed URL back together again.  This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had redundant delimiters, e.g. a ? with an empty query (the draft states that these are equivalent).\n",
    "\n",
    "- urllib.parse.urlsplit: \n",
    "Parse a URL into 5 components:` <scheme>://<netloc>/<path>?<query>#<fragment>`  \n",
    "    `urlsplit(url, scheme='', allow_fragments=True)`\n",
    "\n",
    "- urllib.parse.urlunsplit: \n",
    " Combine the elements of a tuple as returned by urlsplit() into a complete URL as a string. The data argument can be any five-item iterable. This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had unnecessary delimiters (for example, a ? with an empty query; the RFC states that these are equivalent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
