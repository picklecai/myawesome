{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从web抓取信息\n",
    "\n",
    "起源于《Python编程快速上手——让繁琐工作自动化》中的第11章“从web抓取信息”，也有自己生发的及其他书的内容。\n",
    "\n",
    "几个重要的库：  \n",
    "\n",
    "- 1. `webbrowser`\n",
    "- 2. `requests`\n",
    "- 3. `BeautifulSoup`  \n",
    "- 4. `selenium`\n",
    "\n",
    "另外还有`urllib`，但AI Sweigart 说让我忘了这个库，意思是很不好用。\n",
    "\n",
    "---\n",
    "附录：关于HTML\n",
    "\n",
    "**苹果系统中，command+option+I，可以打开或关闭开发者工具，和Windows上的F12是一样的。**  \n",
    "\n",
    "作者建议，**不要用正则表达式来解析HTML**。例如昨天遇到的将class写在a标签中间的那种，对于html来说仍然有效，用正则来预估所有的情况则会非常繁琐。专门用来解析html的模块，例如beautifulsoup，将更不容易出错。[html - RegEx match open tags except XHTML self-contained tags - Stack Overflow](https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython输出各行结果\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  `webbrowser`模块\n",
    "\n",
    "`webbrowser`这个模块，可以直接打开网址。\n",
    "\n",
    "先生成网址，再用webbrowser打开，适合网址有规律的情况。哪些情况适用于生成网址再打开检查的情况？\n",
    "\n",
    "- 动态网址  \n",
    "\n",
    "    - 查询类：内容参数组成新网址，如Google Map\n",
    "    - 解析类：从某段文字中解析出需要的新网址\n",
    "    \n",
    "- 页面内容确认\n",
    "\n",
    "    - 编号类：某种无序数列组成新网址，如小说网站晋江\n",
    "    - 已经获得，手动打开麻烦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 打开小说页面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "for i in range(3000011, 3000020):\n",
    "    url = 'http://www.jjwxc.net/onebook.php?novelid=' + str(i)\n",
    "    webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 打开Google地图上单个城市"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "def mapit(address):\n",
    "    address = re.compile(r'\\s+').sub('+',address) # 这里“+”之前不需要转义符\\\n",
    "    url = 'http://www.google.com/maps/place/' + address\n",
    "    return webbrowser.open(url)\n",
    "\n",
    "address = 'Wuxi,   Jiangsu,   China'    \n",
    "mapit(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 批量打开Google地图的城市群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "def mapcities(cities):\n",
    "    address = []\n",
    "    for city in cities:\n",
    "        address.append(city + ', Jiangsu, China')\n",
    "    for a in address:\n",
    "        a = re.compile(r'\\s+').sub('+',a)\n",
    "        url = 'http://www.google.com/maps/place/' + a\n",
    "        webbrowser.open(url)\n",
    "        \n",
    "cities = ['Wuxi', 'Suzhou', 'Xuzhou', 'Zhengjiang', 'Taizhou']\n",
    "mapcities(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 批量打开简书笔记\n",
    "\n",
    "复制下面这段网址（从workflowy来），用下面的程序批量打开：\n",
    "\n",
    "    [每天一本书 -《思考线》](https://www.jianshu.com/p/ee5e1c32f97d)\n",
    "\t[创意变为现实的最佳方法——《思考线》读后感](https://www.jianshu.com/p/c2132f7e02ae)\n",
    "\t[读思考线 ](https://www.jianshu.com/p/52e2e4dbb08c)\n",
    "\t[极具说服力的书（思考线：让你的创意变为现实的最佳方法](https://book.douban.com/review/7747085/)\n",
    "\t[思考线·思维导图.png (3104×1802)](https://upload-images.jianshu.io/upload_images/14183687-4b46af1a5294edfd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser, pyperclip, re\n",
    "\n",
    "mdUrls = pyperclip.paste().replace('\\t','').split('\\n')\n",
    "urlRegex = re.compile(r'\\((http.*)\\)')\n",
    "for mdUrl in mdUrls:\n",
    "    url = urlRegex.search(mdUrl).group(1)\n",
    "    webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `requests`模块\n",
    "\n",
    "requests文档地址：[Requests: HTTP for Humans™ — Requests 2.21.0 documentation](https://requests.readthedocs.io/en/master/)\n",
    "\n",
    "`requests.get(url)`:  \n",
    "\n",
    "- 类型是`requests.models.Response`\n",
    "- 参数text\n",
    "- 参数headers是类似于字典（字典有`dict.get(key)`返回value的语法）的结构：`requests.structures.CaseInsensitiveDict`，它的键不区分大小写。真正的字典键是区分大小写的。\n",
    "- 参数status_code\n",
    "- 参数encoding\n",
    "- 方法raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ISO-8859-1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "179378"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"\\ufeffThe Project Gutenberg EBook of Romeo and Juliet, by William Shakespeare\\r\\n\\r\\n\\r\\n*******************************************************************\\r\\nTHIS EBOOK WAS ONE OF PROJECT GUTENBERG'S EARLY FILES PRODUCED AT A\\r\\nTIME WHEN PROOFING METHODS AND TOO\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'text/plain; charset=utf-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'Server': 'AliyunOSS', 'Date': 'Fri, 01 Nov 2019 01:39:49 GMT', 'Content-Type': 'text/html', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-oss-request-id': '5DBB8CE55C74183036984F90', 'Last-Modified': 'Thu, 31 Oct 2019 02:27:20 GMT', 'x-oss-object-type': 'Normal', 'x-oss-hash-crc64ecma': '4434422554274640270', 'x-oss-storage-class': 'Standard', 'Content-MD5': 'l2yxdfF3i/9yvmsmNVa0SA==', 'x-oss-server-time': '18', 'Content-Encoding': 'gzip'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: http://inventwithpython.com/page_that_does_not_exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-21c72c8a0df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0murl3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://inventwithpython.com/page_that_does_not_exist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mres3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mres3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://inventwithpython.com/page_that_does_not_exist"
     ]
    }
   ],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import requests\n",
    "import chardet\n",
    "\n",
    "url0 = 'http://www.gutenberg.org/cache/epub/1112/pg1112.txt'\n",
    "url1 = 'http://example.webscraping.com'\n",
    "url2 = 'http://www.engine3d.com'\n",
    "\n",
    "res0 = requests.get(url0)\n",
    "res1 = requests.get(url1)\n",
    "headers = {'user-agent': 'my-app/0.0.1'}\n",
    "res2 = requests.get(url2, headers = headers)\n",
    "\n",
    "# res的基本情况\n",
    "type(res0)\n",
    "res0.status_code == requests.codes.ok\n",
    "res2.encoding\n",
    "\n",
    "# 看res的文本\n",
    "len(res0.text)\n",
    "res0.text[:250]\n",
    "\n",
    "# 看res的headers\n",
    "res0.headers.get('content-type')\n",
    "res2.headers\n",
    "res2.headers.get('user-agent')\n",
    "\n",
    "# 不存在的网址，看res反应\n",
    "url3 = 'http://inventwithpython.com/page_that_does_not_exist'\n",
    "res3 = requests.get(url3)\n",
    "res3.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 能运行起来的第一段程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url0的下载结果： \n",
      "\n",
      "Webpage is download successfully.\n",
      "The beginning texts here:  \n",
      "\n",
      "\n",
      "﻿The Project Gutenberg EBook of Romeo and Juliet, by William Shakespeare\n",
      "\n",
      "\n",
      "*******************************************************************\n",
      "THIS EBOOK WAS ONE OF PROJECT GUTENBERG'S EARLY FILES\n",
      "url3的下载结果： \n",
      "\n",
      "There was a problem: \n",
      "404 Client Error: Not Found for url: http://inventwithpython.com/page_that_does_not_exist\n"
     ]
    }
   ],
   "source": [
    "def download(url):\n",
    "    res = requests.get(url)\n",
    "    try:\n",
    "        res.raise_for_status()\n",
    "        html = res.text\n",
    "        print('Webpage is download successfully.'+'\\n'+'The beginning texts here:  '+'\\n\\n')\n",
    "        print(html[:200])\n",
    "    except Exception as exc :\n",
    "        print('There was a problem: \\n%s' %exc)\n",
    "print('url0的下载结果： \\n')\n",
    "download(url0)\n",
    "print('url3的下载结果： \\n')\n",
    "download(url3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 保存文件到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "79380"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "res = requests.get(url0)\n",
    "res.raise_for_status()\n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'files', 'fiction', 'RomeoAndJuliet.txt')\n",
    "playFile = open(path, 'wb')\n",
    "for chunk in res.iter_content(100000):\n",
    "    playFile.write(chunk)\n",
    "playFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 源代码的编码问题\n",
    "\n",
    "关于Unicode编码的知识：[The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) – Joel on Software](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\n",
    "\n",
    "```\n",
    "encode_type = chardet.detect(html)\n",
    "html = html.decode(encode_type['encoding'])\n",
    "```\n",
    "\n",
    "这里不是靠这两句解决问题的。已经测试过，html是str类型的。\n",
    "\n",
    "用wb模式打开文件，写入内容是 `res.iter_content(100000)`  \n",
    "作者说，使用iter_content是为了确保requests模块即使在**下载巨大**的文件时也**不会消耗太多**内存。\n",
    "\n",
    "**The chunk size is the number of bytes it should read into memory. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method iter_content in module requests.models:\n",
      "\n",
      "iter_content(chunk_size=1, decode_unicode=False) method of requests.models.Response instance\n",
      "    Iterates over the response data.  When stream=True is set on the\n",
      "    request, this avoids reading the content at once into memory for\n",
      "    large responses.  The chunk size is the number of bytes it should\n",
      "    read into memory.  This is not necessarily the length of each item\n",
      "    returned as decoding can take place.\n",
      "    \n",
      "    chunk_size must be of type int or None. A value of None will\n",
      "    function differently depending on the value of `stream`.\n",
      "    stream=True will read data as it arrives in whatever size the\n",
      "    chunks are received. If stream=False, data is returned as\n",
      "    a single chunk.\n",
      "    \n",
      "    If decode_unicode is True, content will be decoded using the best\n",
      "    available encoding based on the response.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(res.iter_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `BeautifulSoup`模块\n",
    "\n",
    "[BeautifulSoup高级应用 之 CSS selectors /CSS 选择器 - Winterto1990的博客 - CSDN博客](https://blog.csdn.net/Winterto1990/article/details/47808949)\n",
    "\n",
    "soup的两类来源：\n",
    "\n",
    "- 1. 从网页获取\n",
    "- 2. 从本地获取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import os\n",
    "\n",
    "# soup的两类来源：\n",
    "# 1. 从网页获取\n",
    "url = 'https://www.tripadvisor.cn/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "example1Soup = bs4.BeautifulSoup(res.text)\n",
    "type(example1Soup)\n",
    "\n",
    "# 2. 从本地获取\n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'files', 'NoStarch.html')\n",
    "example2File = open(path)\n",
    "example2Soup = bs4.BeautifulSoup(example2File.read()) #.read()加了没加没区别。\n",
    "type(example2Soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>TripAdvisor(猫途鹰) - 全球旅游点评,酒店/景点/餐厅,真实旅客评论</title>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<img alt=\"TripAdvisor(猫途鹰)\" class=\"brand-header-Logo__resizeImg--15ZcW\" src=\"https://cc.ddcdn.com/img2/langs/zh_CN/branding/rebrand/TA_logo_primary.svg\"/>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<img alt=\"TripAdvisor(猫途鹰)\" class=\"brand-header-Logo__resizeImg--15ZcW\" src=\"https://cc.ddcdn.com/img2/langs/zh_CN/branding/rebrand/TA_logo_primary.svg\"/>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\ntripSoup.select(\\'input[type=\"radio\"]\\')\\ntripSoup.select_one(\\'input[type=\"radio\"]\\')\\ntripSoup.select(\\'#popularDestinations > div.section > ul.regionContent > li.active > ul > li:nth-child(1) > a > span.thumbCrop > img\\')\\nimages = tripSoup.select(\\'#popularDestinations > div.section > ul.regionContent > li.active > ul > li > a > span.thumbCrop > img\\')\\ntitles = tripSoup.select(\\'#popularDestinations > div.section > ul.regionContent > li.active > ul > li > div.title\\')\\ninfo = []\\nfor title,image in zip(titles, images):\\n    data = {\\n            \\'title\\':((title.get_text()).replace(\\'\\n\\',\\'\\')).replace(\\'游记指南\\',\\'\\'),\\n            \\'image\\':image.get(\\'src\\')\\n        }\\n    info.append(data)\\ninfo\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['height:100%', 'width:100%', 'background-size:cover', 'background-image:none']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lxml解析 \n",
    "import requests\n",
    "import bs4\n",
    "import lxml\n",
    "\n",
    "url = 'https://www.tripadvisor.cn/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "html = res.text\n",
    "tripSoup = bs4.BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tripSoup.select('title')\n",
    "tripSoup.select_one('a>img')\n",
    "tripSoup.select_one('a img')\n",
    "# 网页变了，以下代码失效。\n",
    "'''\n",
    "tripSoup.select('input[type=\"radio\"]')\n",
    "tripSoup.select_one('input[type=\"radio\"]')\n",
    "tripSoup.select('#popularDestinations > div.section > ul.regionContent > li.active > ul > li:nth-child(1) > a > span.thumbCrop > img')\n",
    "images = tripSoup.select('#popularDestinations > div.section > ul.regionContent > li.active > ul > li > a > span.thumbCrop > img')\n",
    "titles = tripSoup.select('#popularDestinations > div.section > ul.regionContent > li.active > ul > li > div.title')\n",
    "info = []\n",
    "for title,image in zip(titles, images):\n",
    "    data = {\n",
    "            'title':((title.get_text()).replace('\\n','')).replace('游记指南',''),\n",
    "            'image':image.get('src')\n",
    "        }\n",
    "    info.append(data)\n",
    "info\n",
    "'''\n",
    "# 不知道为什么读不到背景图像的url\n",
    "tripSoup.select('a>div>ul>li>div')[0]['style'].split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Prashanth!\n",
      "https://www.joelonsoftware.com/2019/09/24/announcing-stack-overflows-new-ceo/\n",
      "The next CEO of Stack Overflow\n",
      "https://www.joelonsoftware.com/2019/03/28/the-next-ceo-of-stack-overflow/\n",
      "Things You Should Never Do, Part I\n",
      "Strategy Letter I: Ben and Jerry’s vs. Amazon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://i1.wp.com/www.joelonsoftware.com/wp-content/uploads/2016/12/Pong.png?w=730&ssl=1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, bs4\n",
    "\n",
    "url = 'https://www.joelonsoftware.com/'\n",
    "res = requests.get(url)\n",
    "htmlSoup = bs4.BeautifulSoup(res.text)\n",
    "\n",
    "import pprint\n",
    "for i in range(2):\n",
    "    # pprint.pprint(htmlSoup.select('div>p>span>a')[i].attrs)\n",
    "    # print(htmlSoup.select('div>p>span>a')[i].get('href'))\n",
    "    # pprint.pprint(htmlSoup.select('header>h2>a')[i].attrs)\n",
    "    print(htmlSoup.select('header>h2>a')[i].text)\n",
    "    print(htmlSoup.select('header>h2>a')[i].get('href'))\n",
    "for i in range(2):\n",
    "    print(htmlSoup.select('div>ul>li>a')[i].text)\n",
    "    \n",
    "htmlSoup.select_one('img')['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>CSDN博客-专业IT技术发表平台</title>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<a href=\"/\">推荐</a>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\t\\t\\t\\t\\tCSDN产品公告第2期：博客支持视频、专栏文章拖拽排序、APP霸王课来袭……\\t\\t\\t\\t\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, bs4\n",
    "\n",
    "url = 'https://blog.csdn.net' \n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = bs4.BeautifulSoup(res.text)\n",
    "soup.select('title')\n",
    "# soup.select('div nth-of-type(0)') 在ipython中不好用\n",
    "# soup.select('body a')[:3]\n",
    "# soup.select('div>ul>li.active')\n",
    "# soup.select('.carousel-caption, p.name')\n",
    "soup.select('a[href]')[0]\n",
    "soup.select(\"a[href$='102605809']\")[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 下载古腾堡中文书\n",
    "\n",
    "突然想下载古腾堡的书下来。挑选中文的试试吧。  \n",
    "\n",
    "【下载】\n",
    "1. 通过主页面提取出txt的url\n",
    "2. 使用上面的功能下载这些。\n",
    "\n",
    "【繁体转简体】\n",
    "找到对应的库 \n",
    "\n",
    "> 不需要什么安装方法，只需要把这两个文件下载下来，保存到与代码同一目录下即可\n",
    "```\n",
    "https://raw.githubusercontent.com/skydark/nstools/master/zhtools/langconv.py  \n",
    "https://raw.githubusercontent.com/skydark/nstools/master/zhtools/zh_wiki.py\n",
    "```\n",
    "\n",
    "#### 3.2.1 下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载txt\n",
    "import requests\n",
    "import bs4\n",
    "import os\n",
    "\n",
    "url = 'https://www.gutenberg.org/browse/languages/zh'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "fictionSoup = bs4.BeautifulSoup(res.text)\n",
    "fictionList = fictionSoup.select(\"li.pgdbetext a[href^='/ebooks']\")\n",
    "for i in range(len(fictionList)):\n",
    "    fileName = fictionList[i].get_text()    \n",
    "    if '/' in fileName:\n",
    "        fileName = fileName.replace('/', ' ')\n",
    "    if '\\\\' in fileName:\n",
    "        fileName = fileName.replace('\\\\', ' ')\n",
    "    file = os.path.join(os.path.dirname(os.getcwd()), 'files', 'fiction', fileName +'.txt')\n",
    "    if os.path.exists(file):\n",
    "        fileName = fileName + '_new'\n",
    "        file = os.path.join(os.path.dirname(os.getcwd()), 'files', 'fiction', fileName +'.txt')\n",
    "    fictionID = (fictionList[i].get('href')).split('/')[2]\n",
    "    fictionUrl = 'https://www.gutenberg.org/files/' + fictionID + '/' + fictionID + '-0.txt'\n",
    "    with open(file ,'wb') as fictionFile:\n",
    "        resFiction = requests.get(fictionUrl)\n",
    "        for chunk in resFiction.iter_content(100000):\n",
    "            fictionFile.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一共下载了475本txt文本格式的电子书。  \n",
    "\n",
    "现在看txt格式的都可以下载，试试其他格式的：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载epub\n",
    "\n",
    "file = os.path.join(os.path.dirname(os.getcwd()), 'files', 'fiction', '玉樓春.epub')\n",
    "url = 'https://www.gutenberg.org/ebooks/25422.epub.noimages?session_id=3c29b07a963878c5cd004f277b6d1d0adb08d623'\n",
    "with open(file ,'wb') as fictionFile:\n",
    "        resFiction = requests.get(url)\n",
    "        for chunk in resFiction.iter_content(100000):\n",
    "            fictionFile.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 转换简繁体  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'玉楼春'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langconv import *\n",
    "\n",
    "sentence = '玉樓春'\n",
    "Converter('zh-hans').convert(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要想批量转换，需要：  \n",
    "\n",
    "1. 转换文件名  \n",
    "2. 建立新文件——考虑到有些文件名已经是简体，保险的方法就是再建立一个简体文件夹。  \n",
    "3. 读取文件中的内容\n",
    "4. 转换文件内容  \n",
    "5. 写入新文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langconv import Converter\n",
    "\n",
    "pathFanti = os.path.join(os.path.dirname(os.getcwd()), 'files', 'fiction', 'fanti')\n",
    "pathJianti = os.path.join(os.path.dirname(os.getcwd()), 'files', 'fiction', 'jianti')\n",
    "filesFanti = os.listdir(pathFanti) #把这个目录下的所有文件都读出来\n",
    "for fileName in filesFanti:\n",
    "    if fileName.split('.')[-1] != 'txt':\n",
    "        filesFanti.remove(fileName)\n",
    "for fileNameFanti in filesFanti:\n",
    "    fileNameJianti = Converter('zh-hans').convert(fileNameFanti)\n",
    "    with open(os.path.join(pathJianti, fileNameJianti), 'w') as fileJianti:\n",
    "        with open(os.path.join(pathFanti, fileNameFanti)) as fileFanti:\n",
    "            contentFanti = fileFanti.readlines()\n",
    "            for sentenceFanti in contentFanti:\n",
    "                sentenceJianti = Converter('zh-hans').convert(sentenceFanti)\n",
    "                fileJianti.write(sentenceJianti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了一个打不开的，其他都转换成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Google自动查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googling...\n"
     ]
    }
   ],
   "source": [
    "# _*_coding:utf-8_*_\n",
    "import requests, bs4, webbrowser,re\n",
    "\n",
    "def googleit(query):\n",
    "    \n",
    "    #打开查询结果页面\n",
    "    if '' in query:\n",
    "        query = re.compile(r'\\s+').sub('+', query)\n",
    "    url = 'http://www.google.com/search?q=' + query\n",
    "    print('Googling...')\n",
    "    headers = {'User-Agent':'Mozilla/8.0 (compatible; MSIE 8.0; Windows 7)'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status()\n",
    "    \n",
    "    #选择结果页面\n",
    "    soup = bs4.BeautifulSoup(res.text)\n",
    "    linkElems = soup.select('.r a')\n",
    "    \n",
    "    #打开前5个页面\n",
    "    numOpen = min(5, len(linkElems))\n",
    "    for i in range(numOpen):\n",
    "        webbrowser.open('http://google.com' + linkElems[i].get('href'))\n",
    "        # print(linkElems[i].get('href'))\n",
    "query = 'python webscraping'\n",
    "googleit(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 下载xkcd漫画\n",
    "\n",
    "这是第一次尝试下载图片。先开始是教材上的程序，后来自己又重新写了一下。\n",
    "\n",
    "#### 3.4.1 标准程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That is wrong. Downloading image is http://www.xkcd.com/2067/asset/challengers_header.png ...\n",
      "Could not find comic image.\n",
      "Could not find comic image.\n",
      "That is wrong. Downloading image is http://www.xkcd.com/1525/bg.png ...\n",
      "Could not find comic image.\n",
      "Could not find comic image.\n"
     ]
    }
   ],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "import requests, bs4,os\n",
    "\n",
    "url = 'http://xkcd.com'\n",
    "# os.makedirs('xkcd', exist_ok=True)\n",
    "while not url.endswith('#'):\n",
    "    #下载网页\n",
    "    # print('Downloading page %s ...'%url)\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(res.text)\n",
    "    \n",
    "    #寻找漫画\n",
    "    comicElem = soup.select('#comic img')\n",
    "    if comicElem == []:\n",
    "        print('Could not find comic image.')\n",
    "    else:\n",
    "        try:\n",
    "            comicUrl = 'http:'+ comicElem[0].get('src')\n",
    "            # print('Downloading image is %s ...'%comicUrl)\n",
    "            res = requests.get(comicUrl)\n",
    "            res.raise_for_status()  \n",
    "        except:\n",
    "            comicUrl = 'http://www.xkcd.com'+ comicElem[0].get('src')\n",
    "            print('That is wrong. Downloading image is %s ...'%comicUrl)    \n",
    "            res = requests.get(comicUrl)\n",
    "            res.raise_for_status() \n",
    "\n",
    "    #保存漫画\n",
    "    # imageFile = open(os.path.join('xkcd', os.path.basename(comicUrl)), 'wb')\n",
    "    imageFile = open(os.path.dirname(os.getcwd()) + '/files/xkcd/' + os.path.basename(comicUrl), 'wb')\n",
    "    for chunk in res.iter_content(100000):\n",
    "        imageFile.write(chunk)\n",
    "    imageFile.close() \n",
    "\n",
    "    #找前一张漫画\n",
    "    prevLink = soup.select('a[rel=\"prev\"]')[0]\n",
    "    url = 'http://xkcd.com' + prevLink.get('href')\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image is http://imgs.xkcd.com/comics/pie_charts.png ...\n"
     ]
    }
   ],
   "source": [
    "url = 'https://xkcd.com/2031/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(res.text)\n",
    "comicElem = soup.select('#comic img')\n",
    "try:\n",
    "    comicUrl = 'http:'+ comicElem[0].get('src')\n",
    "    print('Downloading image is %s ...'%comicUrl)\n",
    "    res = requests.get(comicUrl)\n",
    "    res.raise_for_status()  \n",
    "except:\n",
    "    comicUrl = 'http://www.xkcd.com'+ comicElem[0].get('src')\n",
    "    print('That is wrong. Downloading image is %s ...'%comicUrl)    \n",
    "    res = requests.get(comicUrl)\n",
    "    res.raise_for_status() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "明白了，这里用的是canvas，不是img。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2031和1813都出现的错误：  \n",
    "\n",
    "SysCallError                              Traceback (most recent call last)\n",
    "\n",
    "SSLError: HTTPSConnectionPool(host='xkcd.com', port=443): Max retries exceeded with url: /1813/ (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.4.2 重新下载xkcd漫画\n",
    "\n",
    "在知道了漫画作者门罗就是《万物解释者》作者后，决定重新下载xkcd漫画。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import os\n",
    "\n",
    "url = 'https://xkcd.com/1'\n",
    "while True:\n",
    "    # 获取当前页面的漫画地址\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(res.text)\n",
    "    try:\n",
    "        # 当前页面存在漫画的静态图片地址\n",
    "        srcComic = soup.select_one('#comic img').get('src')\n",
    "        urlComic = 'https:'+ srcComic\n",
    "    except:\n",
    "        # 没有漫画地址就直接找下一页\n",
    "        srcPrev = soup.select_one(\".comicNav a[rel='prev']\").get('href')\n",
    "        print(srcPrev)\n",
    "        url = 'https://xkcd.com' + srcPrev\n",
    "        continue\n",
    "    \n",
    "    # 存储当前漫画到本地\n",
    "    fileName = srcComic.split('/')[-1]\n",
    "    filePath = os.path.join(os.path.dirname(os.getcwd()), 'files', 'xkcd', fileName)\n",
    "    with open(filePath, 'wb') as comicFile:\n",
    "        resComic = requests.get(urlComic)\n",
    "        for chunk in resComic.iter_content(100000):\n",
    "            comicFile.write(chunk)\n",
    "    \n",
    "    # 获取前一页的页面地址\n",
    "    srcPrev = soup.select_one(\".comicNav a[rel='prev']\").get('href')\n",
    "    # 到了第一幅漫画的页面\n",
    "    if srcPrev == '#':\n",
    "        break\n",
    "    print(srcPrev)\n",
    "    url = 'https://xkcd.com' + srcPrev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有问题的：2198, 2067，1663，1608，1525，1416，1350  \n",
    "\n",
    "2198、1663、1608、1525、1416都是游戏，页面有交互，非普通静态图片。1416会放大，嵌入了一个框架网页。1350无内容。\n",
    "\n",
    "2067会放大，其中有链接，也不是普通图片。错误显示为：  \n",
    "\n",
    "```\n",
    "MissingSchema: Invalid URL 'https:/2067/asset/challengers_header.png': No schema supplied. Perhaps you meant http://https:/2067/asset/challengers_header.png?\n",
    "```\n",
    "\n",
    "1052-878之间一次性完成，无意外。874-787一次性完成。691-483一次性完成。446-250一次性完成\n",
    "\n",
    "超时的错误为：  \n",
    "\n",
    "```\n",
    "SSLError: HTTPSConnectionPool(host='xkcd.com', port=443): Max retries exceeded with url: /240/ (Caused by SSLError(SSLError(\"bad handshake: SysCallError(60, 'ETIMEDOUT')\")))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "1. 需要写一个try-except，出了意外，直接找prev按钮继续走下去。 \n",
    "   try-except无法解决2067的问题。\n",
    "2. 对于timeout怎么应对？\n",
    "\n",
    "目前程序的三个问题：  \n",
    "\n",
    "1. try-except无法解决2067的问题  \n",
    "2. timeout无法解决  \n",
    "3. 下载速度太慢，平均每小时只能下载200-300张漫画，全部2200张漫画需要七八个小时才能下完。  \n",
    "\n",
    "问题三可以用多线程来解决。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单独下载一副漫画\n",
    "\n",
    "url = 'https://xkcd.com/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(res.text)\n",
    "srcComic = soup.select_one('#comic img').get('src')\n",
    "urlComic = 'https:'+ srcComic\n",
    "\n",
    "# 存储当前漫画到本地\n",
    "fileName = srcComic.split('/')[-1]\n",
    "filePath = os.path.join(os.path.dirname(os.getcwd()), 'files', 'xkcd', fileName)\n",
    "with open(filePath, 'wb') as comicFile:\n",
    "    resComic = requests.get(urlComic)\n",
    "    for chunk in resComic.iter_content(100000):\n",
    "        comicFile.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 多线程下载xkcd漫画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download End.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import threading\n",
    "import os\n",
    "\n",
    "def downloadComic(startComic, endComic):\n",
    "    for comicID in range(startComic, endComic):\n",
    "        # 获取漫画地址\n",
    "        res = requests.get('https://xkcd.com/%s'%str(comicID))\n",
    "        soup = bs4.BeautifulSoup(res.text)\n",
    "        comicElem = soup.select('#comic img')\n",
    "        if comicElem == []:\n",
    "            print('Could not find comic img: %s'%str(comicID))\n",
    "        else:\n",
    "            srcComic = comicElem[0].get('src')\n",
    "            urlComic = 'https:'+ srcComic\n",
    "            # 存储到本地\n",
    "            fileName = str(comicID) + '-' + srcComic.split('/')[-1]\n",
    "            filePath = os.path.join(os.path.dirname(os.getcwd()), 'files', 'xkcd', fileName)\n",
    "            if os.path.exists(filePath):\n",
    "                continue\n",
    "            with open(filePath, 'wb') as comicFile:\n",
    "                resComic = requests.get(urlComic)\n",
    "                for chunk in resComic.iter_content(100000):\n",
    "                    comicFile.write(chunk)\n",
    "\n",
    "downloadTreads = []\n",
    "for i in range(1, 81, 10):\n",
    "    downloadTread = threading.Thread(target=downloadComic, args=[i, i+10])\n",
    "    downloadTreads.append(downloadTread)\n",
    "    downloadTread.start()\n",
    "for downloadTread in downloadTreads:\n",
    "    downloadTread.join()\n",
    "print('Download End.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了顺利地在所有线程结束后打印‘Download End.’，必须所有线程都没有崩溃才行。timeout一旦出现，这个程序就处于永远结束不了的状态了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 下载极客漫画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4, os\n",
    "\n",
    "for i in range(1,6):\n",
    "    url = 'https://linux.cn/talk/comic/index.php?page=' + str(i)\n",
    "    headers = {'User-Agent':'Mozilla/8.0 (compatible; MSIE 8.0; Windows 7)'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(res.text)\n",
    "    for s in soup.select('h2 span[class=\"title\"] a'):\n",
    "        comicUrl = s.get('href')\n",
    "        comicRes = requests.get(comicUrl, headers=headers)\n",
    "        comicRes.raise_for_status()\n",
    "        comicSoup = bs4.BeautifulSoup(comicRes.text)\n",
    "        comicImageUrl = comicSoup.select('#article_content img')[0].get('src')\n",
    "        comicImageRes = requests.get(comicImageUrl, headers=headers)\n",
    "        imageFile = open(os.path.dirname(os.getcwd()) + '/files/jkmh/' + os.path.basename(comicImageUrl), 'wb')\n",
    "        for chunk in comicImageRes.iter_content(100000):\n",
    "            imageFile.write(chunk)\n",
    "        imageFile.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 玩豆瓣\n",
    "\n",
    "#### 3.6.1 豆瓣top250图书\n",
    "\n",
    "豆瓣有个top250的图书榜单，读取其中书名、作者和评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '红楼梦', 'author': '曹雪芹', 'score': '9.6'}\n",
      "{'title': '海贼王:ONEPIECE', 'author': '尾田荣一郎', 'score': '9.5'}\n"
     ]
    }
   ],
   "source": [
    "import requests, bs4, lxml, re\n",
    "urls = []\n",
    "for i in range(0,250,25):\n",
    "    urls.append('https://book.douban.com/top250?start=' + str(i))\n",
    "info = []\n",
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    html = res.text\n",
    "    doubanBookSoup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    titles = doubanBookSoup.select('a[title]')\n",
    "    scores = doubanBookSoup.select('span[class=\"rating_nums\"]')\n",
    "    authors = doubanBookSoup.select('p.pl')\n",
    "    for title, author, score in zip(titles, authors, scores):\n",
    "        data = {\n",
    "            'title':((title.get_text()).replace('\\n','')).replace(' ','') ,\n",
    "            'author':re.compile(r'(\\[\\w+\\])?(\\w)+(·)?(\\w+)(·\\w+)?').search(author.get_text()).group(),\n",
    "            'score':score.get_text()\n",
    "        }\n",
    "        info.append(data)\n",
    "\n",
    "for i in info:\n",
    "    if 9.5<=float(i['score'])<9.7:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': '红楼梦', 'Rating': '9.6', 'Author': '[清] 曹雪芹 著 '}\n",
      "{'Title': '海贼王', 'Rating': '9.5', 'Author': '尾田荣一郎 '}\n"
     ]
    }
   ],
   "source": [
    "# 2019.11.01重新写一遍\n",
    "import requests\n",
    "import bs4\n",
    "import lxml\n",
    "import os\n",
    "\n",
    "topBooks = []\n",
    "for pageNum in range(0,250,25):\n",
    "    url = 'https://book.douban.com/top250?start=' + str(pageNum)\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "    for i in range(25):\n",
    "        info = soup.select('p.pl')[i].text\n",
    "        data = {\n",
    "            'Title':soup.select('.pl2 a')[i]['title'],\n",
    "            'Rating':soup.select('.rating_nums')[i].text,    \n",
    "            'Author': info.split('/')[0]\n",
    "        }\n",
    "        topBooks.append(data)\n",
    "for book in topBooks:\n",
    "    if float(book['Rating'])>=9.5:\n",
    "        print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.2 豆瓣标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://sec.douban.com/b?r=https%3A%2F%2Fbook.douban.com%2Ftag%2F%25E6%2595%2599%25E8%2582%25B2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9183a9339a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murlTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://book.douban.com/tag/%E6%95%99%E8%82%B2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresTag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msoupTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresTag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://sec.douban.com/b?r=https%3A%2F%2Fbook.douban.com%2Ftag%2F%25E6%2595%2599%25E8%2582%25B2"
     ]
    }
   ],
   "source": [
    "# 单标签\n",
    "import requests, bs4, lxml\n",
    "import os, openpyxl, re, threading\n",
    "\n",
    "urlTag = 'https://book.douban.com/tag/%E6%95%99%E8%82%B2'  \n",
    "resTag = requests.get(urlTag)\n",
    "resTag.raise_for_status()\n",
    "soupTag = bs4.BeautifulSoup(resTag.text, 'lxml')\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheetTag = wb.create_sheet()\n",
    "tag = soupTag.select('h1')[0].split(': ')[1]\n",
    "sheetTag.title = tag\n",
    "sheetTag['A1'], sheetTag['B1'], sheetTag['C1'] = 'Label', 'Title', 'Author'\n",
    "sheetTag['D1'], sheetTag['E1'] = 'Rating', 'Link' \n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'files', 'douban', 'tags.xlsx')\n",
    "wb.save(path)\n",
    "wb.close()\n",
    "\n",
    "def saveContent(tag):\n",
    "    total = 0\n",
    "    while True:\n",
    "        num = len(soupTag.select('h2 a'))\n",
    "        if num == 0:\n",
    "            break\n",
    "        for i in range(num):\n",
    "            sheetTag['A'+str(i+2+total)] = soupTag.select('h1')[0].text.split(': ')[1]\n",
    "            sheetTag['B'+str(i+2+total)] = soupTag.select('h2 a')[i].get('title')\n",
    "            sheetTag['C'+str(i+2+total)] = re.compile(r'\\s+').sub('', soupTag.select('div.pub')[i].text).split('/')[0]\n",
    "            sheetTag['E'+str(i+2+total)] = soupTag.select('h2 a')[i].get('href') \n",
    "            if '少于10人评价' in soupTag.select('.clearfix .pl')[i].text:\n",
    "                sheetTag['D'+str(i+2+total)] = ''\n",
    "            else:\n",
    "                sheetTag['D'+str(i+2+total)] = soupTag.select('.info .clearfix')[i].select('.rating_nums')[0].text\n",
    "        total = total + num\n",
    "        urlTag = 'https://book.douban.com' + soupTag.select('.next link')[0].get('href')\n",
    "    path = os.path.join(os.path.dirname(os.getcwd()), 'files', 'douban', 'tags.xlsx')\n",
    "    wb.save(path)\n",
    "    wb.close()\n",
    "\n",
    "saveThread = threading.Thread(target=saveContent, args=[tag])\n",
    "saveThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-189e67092bdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0msaveThreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0msaveThread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaveContent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0msaveThreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveThread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0msaveThread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 多标签\n",
    "import requests, bs4, lxml\n",
    "import os, openpyxl, re, threading\n",
    "\n",
    "url = 'https://book.douban.com/tag/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "wb = openpyxl.Workbook()\n",
    "tags = []\n",
    "for tagID in range(len(soup.select('.tagCol a'))):\n",
    "    urlTag = 'https://book.douban.com' + soup.select('.tagCol a')[tagID].get('href')   \n",
    "    sheetTag = wb.create_sheet()\n",
    "    tag = soup.select('.tagCol a')[tagID].text\n",
    "    sheetTag.title = tag\n",
    "    tags.append(tag)\n",
    "    sheetTag['A1'], sheetTag['B1'], sheetTag['C1'] = 'Label', 'Title', 'Author'\n",
    "    sheetTag['D1'], sheetTag['E1'] = 'Rating', 'Link' \n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'files', 'douban', 'tags.xlsx')\n",
    "wb.save(path)\n",
    "wb.close()\n",
    "\n",
    "def saveContent(tag):\n",
    "    urlTag = 'https://book.douban.com/tag/' + tag\n",
    "    sheetTag = wb[tag]\n",
    "    total = 0\n",
    "    while True:\n",
    "        resTag = requests.get(urlTag)\n",
    "        resTag.raise_for_status()\n",
    "        soupTag = bs4.BeautifulSoup(resTag.text, 'lxml')\n",
    "        num = len(soupTag.select('h2 a'))\n",
    "        if num == 0:\n",
    "            break\n",
    "        for i in range(num):\n",
    "            sheetTag['A'+str(i+2+total)] = soupTag.select('h1')[0].text.split(': ')[1]\n",
    "            sheetTag['B'+str(i+2+total)] = soupTag.select('h2 a')[i].get('title')\n",
    "            sheetTag['C'+str(i+2+total)] = re.compile(r'\\s+').sub('', soupTag.select('div.pub')[i].text).split('/')[0]\n",
    "            sheetTag['E'+str(i+2+total)] = soupTag.select('h2 a')[i].get('href') \n",
    "            if '少于10人评价' in soupTag.select('.clearfix .pl')[i].text:\n",
    "                sheetTag['D'+str(i+2+total)] = ''\n",
    "            else:\n",
    "                sheetTag['D'+str(i+2+total)] = soupTag.select('.info .clearfix')[i].select('.rating_nums')[0].text\n",
    "        total = total + num\n",
    "        urlTag = 'https://book.douban.com' + soupTag.select('.next link')[0].get('href')\n",
    "    path = os.path.join(os.path.dirname(os.getcwd()), 'files', 'douban', 'tags.xlsx')\n",
    "    wb.save(path)\n",
    "    wb.close()\n",
    "\n",
    "saveThreads = []\n",
    "for i in range(2):\n",
    "    saveThread = threading.Thread(target=saveContent, args=[tags[i]])\n",
    "    saveThreads.append(saveThread)\n",
    "    saveThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://book.douban.com/tag/'\n",
    "res = requests.get(url, 'lxml')\n",
    "soup = bs4.BeautifulSoup(res.text)\n",
    "len(soup.select('.tagCol a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.7 赵雅芝贴吧内容读取 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 存入字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, bs4, lxml\n",
    "\n",
    "info = []\n",
    "for i in range(0, 100, 50):\n",
    "    url = 'http://tieba.baidu.com/f?kw=%E8%B5%B5%E9%9B%85%E8%8A%9D&ie=utf-8&pn=' + str(i)\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    html = res.text\n",
    "    yazhiSoup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    titles = yazhiSoup.select('a[class=\"j_th_tit\"]')\n",
    "    replies = yazhiSoup.select('span[class=\"threadlist_rep_num center_text\"]')\n",
    "    for title, reply in zip(titles, replies):\n",
    "        data = {\n",
    "            \"title\":title.get_text(),\n",
    "            \"replies\":reply.get_text(),\n",
    "            \"link\":'http://tieba.baidu.com' + title['href']\n",
    "        }\n",
    "        info.append(data)\n",
    "file_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '【典雅一生】收集10000句：赵雅芝我爱你', 'replies': '31627', 'link': 'http://tieba.baidu.com/p/3412726961'}\n",
      "{'title': '【典雅一生】赵雅芝', 'replies': '2654', 'link': 'http://tieba.baidu.com/p/5144633788'}\n",
      "{'title': '【典雅一生】新小说《蓦然回首，浮生若梦》', 'replies': '6894', 'link': 'http://tieba.baidu.com/p/4872399665'}\n"
     ]
    }
   ],
   "source": [
    "for i in info:\n",
    "    if int(i['replies'])>2000:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '【典雅一生】新白娘子传奇的删减', 'replies': '38', 'link': 'http://tieba.baidu.com/p/5873317948'}\n",
      "{'title': '【典雅一生】《新白娘子传奇》曾删减过部分内容吗？', 'replies': '346', 'link': 'http://tieba.baidu.com/p/1958610478'}\n",
      "{'title': '【典雅一生】凯杰即将出演新新白娘子传奇里的仕林了，还是小小期', 'replies': '9', 'link': 'http://tieba.baidu.com/p/6083013894'}\n",
      "{'title': '《新白娘子传奇》1-50集下载（内有下载地址）', 'replies': '45', 'link': 'http://tieba.baidu.com/p/8705594'}\n",
      "{'title': '【典雅一生】《新白娘子传奇》芝姐白素贞好美', 'replies': '0', 'link': 'http://tieba.baidu.com/p/6093271906'}\n",
      "{'title': '【典雅一生】求。新白娘子传奇，谁有？', 'replies': '18', 'link': 'http://tieba.baidu.com/p/5807575411'}\n",
      "{'title': '【典雅一生】《新白娘子传奇》高清大图剧照', 'replies': '1811', 'link': 'http://tieba.baidu.com/p/2476521385'}\n",
      "{'title': '【典雅一生】新白娘子传奇', 'replies': '1', 'link': 'http://tieba.baidu.com/p/6080937969'}\n"
     ]
    }
   ],
   "source": [
    "for i in info:\n",
    "    if '新白娘子传奇' in i['title']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 存入text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4, lxml\n",
    "\n",
    "path = './yazhitieba/'\n",
    "file_txt = open(path + 'yazhi.txt', 'w+')\n",
    "file_txt.write('-------------------Title-----------------------replies----------------------link-------------------')\n",
    "file_txt.write('\\n')\n",
    "for i in range(0, 100, 50):\n",
    "    url = 'http://tieba.baidu.com/f?kw=%E8%B5%B5%E9%9B%85%E8%8A%9D&ie=utf-8&pn=' + str(i)\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    html = res.text\n",
    "    yazhiSoup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    titles = yazhiSoup.select('a[class=\"j_th_tit\"]')\n",
    "    replies = yazhiSoup.select('span[class=\"threadlist_rep_num center_text\"]')\n",
    "    for title, reply in zip(titles, replies):\n",
    "        data = {\n",
    "            \"title\":title.get_text(),\n",
    "            \"replies\":reply.get_text(),\n",
    "            \"link\":'http://tieba.baidu.com' + title['href']\n",
    "        }        \n",
    "        file_txt.write(data['title'])\n",
    "        file_txt.write('  ')\n",
    "        file_txt.write(data['replies'])\n",
    "        file_txt.write('  ')\n",
    "        file_txt.write(data['link'])\n",
    "        file_txt.write('\\n')\n",
    "file_txt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 写入Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caimeijuan/anaconda/envs/python35/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated function get_active_sheet (Use the .active property).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import requests, bs4, lxml, openpyxl\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.get_active_sheet()\n",
    "sheet.title = 'Tieba'\n",
    "sheet['A1'] = 'Title'\n",
    "sheet['B1'] = 'Replies'\n",
    "sheet['C1'] = 'Link'\n",
    "\n",
    "for i in range(0, 100, 50):\n",
    "    url = 'http://tieba.baidu.com/f?kw=%E8%B5%B5%E9%9B%85%E8%8A%9D&ie=utf-8&pn=' + str(i)\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    html = res.text\n",
    "    yazhiSoup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    titles = yazhiSoup.select('a[class=\"j_th_tit\"]')\n",
    "    replies = yazhiSoup.select('span[class=\"threadlist_rep_num center_text\"]')\n",
    "    numbers = range(2, 5000)\n",
    "    for title, reply, number in zip(titles, replies, numbers):\n",
    "        sheet['A'+str(number)] = title.get_text()\n",
    "        sheet['B'+str(number)] = reply.get_text()\n",
    "        sheet['C'+str(number)] = 'http://tieba.baidu.com' + title['href']\n",
    "\n",
    "path = './yazhitieba/'\n",
    "wb.save(path + 'yazhi.xlsx')\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. `selenium`模块\n",
    "\n",
    "折腾过程见教程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果browser赋值时打开的窗口关掉了，让browser.get(url)就会出错。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: Chrome version must be between 70 and 73\n  (Driver info: chromedriver=73.0.3683.68 (47787ec04b6e38e22703e856e101e840b65afe72),platform=Mac OS X 10.14.4 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-8e5204dbccfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/caimeijuan/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/chrome/chromedriver'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbrowser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mremote_server_addr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     keep_alive=keep_alive),\n\u001b[0;32m---> 81\u001b[0;31m                 desired_capabilities=desired_capabilities)\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    155\u001b[0m             warnings.warn(\"Please use FirefoxOptions to set browser profile\",\n\u001b[1;32m    156\u001b[0m                           DeprecationWarning, stacklevel=2)\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSwitchTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mobile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    250\u001b[0m         parameters = {\"capabilities\": w3c_caps,\n\u001b[1;32m    251\u001b[0m                       \"desiredCapabilities\": capabilities}\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'sessionId'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSessionNotCreatedException\u001b[0m: Message: session not created: Chrome version must be between 70 and 73\n  (Driver info: chromedriver=73.0.3683.68 (47787ec04b6e38e22703e856e101e840b65afe72),platform=Mac OS X 10.14.4 x86_64)\n"
     ]
    }
   ],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "from selenium import webdriver\n",
    "\n",
    "path = '/Users/caimeijuan/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/chrome/chromedriver'\n",
    "browser = webdriver.Chrome(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found <img> element with that class name!\n"
     ]
    }
   ],
   "source": [
    "url = 'http://inventwithpython.com'\n",
    "browser.get(url)\n",
    "\n",
    "try:\n",
    "    elem = browser.find_element_by_class_name('card-img-top')\n",
    "    print('Found <%s> element with that class name!' %(elem.tag_name))\n",
    "except:\n",
    "    print('Was not able to find an element with that name.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selenium.webdriver.remote.webelement.WebElement"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser = webdriver.Chrome(path)\n",
    "url = 'http://inventwithpython.com'\n",
    "browser.get(url)\n",
    "\n",
    "linkElem = browser.find_element_by_link_text('Read Online for Free')\n",
    "type(linkElem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkElem.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "真的把这个链接打开了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 登录gmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://gmail.com'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出input元素：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classElem = browser.find_element_by_class_name('whsOnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idElem = browser.find_element_by_id('identifierId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameElem = browser.find_element_by_name('identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classElem == idElem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idElem == nameElem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagElem = browser.find_element_by_tag_name('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameElem == tagElem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsElem_div = browser.find_elements_by_tag_name('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsElem_a = browser.find_elements_by_tag_name('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 填写email帐号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "tagsElem_input = browser.find_elements_by_tag_name('input')\n",
    "email = tagsElem_input[0]\n",
    "email.clear()\n",
    "email.send_keys(getpass.getpass())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试图毕其功于一役，失败。错误提示是：**元素不可见**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsElem_input = browser.find_elements_by_tag_name('input')\n",
    "email = None\n",
    "password = None\n",
    "for t in tagsElem_input:\n",
    "    if t.get_property('type')=='email':\n",
    "        email = t\n",
    "    elif t.get_property('type')=='password':\n",
    "        password = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotVisibleException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=73.0.3683.103)\n  (Driver info: chromedriver=73.0.3683.68 (47787ec04b6e38e22703e856e101e840b65afe72),platform=Mac OS X 10.14.4 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mElementNotVisibleException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e2c2fb1dd386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'caimeijuan@gmail.com'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpassword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'363265911'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;34m\"\"\"Clears the text if it's a text entry element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLEAR_ELEMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mElementNotVisibleException\u001b[0m: Message: element not interactable\n  (Session info: chrome=73.0.3683.103)\n  (Driver info: chromedriver=73.0.3683.68 (47787ec04b6e38e22703e856e101e840b65afe72),platform=Mac OS X 10.14.4 x86_64)\n"
     ]
    }
   ],
   "source": [
    "email.clear()\n",
    "email.send_keys('xxxxxxx@gmail.com')\n",
    "password.clear()\n",
    "password.send_keys('********')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 点击下一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classElem_btn = browser.find_element_by_class_name('RveJvd')\n",
    "classElem_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 填写密码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "tagsElem_input = browser.find_elements_by_tag_name('input')\n",
    "password = tagsElem_input[2]\n",
    "password.send_keys(getpass.getpass())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 点击下一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classElem_btn = browser.find_element_by_class_name('RveJvd')\n",
    "classElem_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是很久不登录需要选择风格的画面。一般不会遇到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameElem_btn = browser.find_element_by_name('welcome_dialog_next')\n",
    "nameElem_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeElem_btn = browser.find_element_by_name('ok')\n",
    "typeElem_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "逐步登录成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "————————————合并成一个完整程序————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your email account: ········\n",
      "Input your password: ········\n",
      "identifier\n",
      "hiddenPassword\n",
      "ca\n",
      "ct\n",
      "pstMsg\n",
      "checkConnection\n",
      "checkedDomains\n"
     ]
    },
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=73.0.3683.103)\n  (Driver info: chromedriver=73.0.3683.68 (47787ec04b6e38e22703e856e101e840b65afe72),platform=Mac OS X 10.14.4 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-67b0fa918efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0memail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input your email account: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input your password: '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#不显示输入值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mgmailSignin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-67b0fa918efd>\u001b[0m in \u001b[0;36mgmailSignin\u001b[0;34m(email, password)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mpasswordElem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElem_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mpasswordElem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# 点击下一步\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36msend_keys\u001b[0;34m(self, *value)\u001b[0m\n\u001b[1;32m    477\u001b[0m         self._execute(Command.SEND_KEYS_TO_ELEMENT,\n\u001b[1;32m    478\u001b[0m                       {'text': \"\".join(keys_to_typing(value)),\n\u001b[0;32m--> 479\u001b[0;31m                        'value': keys_to_typing(value)})\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# RenderedWebElement Items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=73.0.3683.103)\n  (Driver info: chromedriver=73.0.3683.68 (47787ec04b6e38e22703e856e101e840b65afe72),platform=Mac OS X 10.14.4 x86_64)\n"
     ]
    }
   ],
   "source": [
    "#_*_coding:utf-8_*_\n",
    "from selenium import webdriver\n",
    "import getpass\n",
    "\n",
    "path = '/Users/caimeijuan/anaconda/envs/python35/lib/python3.7/site-packages/selenium/webdriver/chrome/chromedriver'\n",
    "browser = webdriver.Chrome(path)\n",
    "\n",
    "def gmailSignin(email, password):\n",
    "    #打开登录界面\n",
    "    url = 'http://gmail.com'\n",
    "    browser.get(url)\n",
    "\n",
    "    # 填写email帐号\n",
    "    tagsElem_input = browser.find_elements_by_tag_name('input')\n",
    "    emailElem = tagsElem_input[0]\n",
    "    emailElem.clear()\n",
    "    emailElem.send_keys(email)\n",
    "\n",
    "    # 点击下一步\n",
    "    classElem_btn = browser.find_element_by_class_name('RveJvd')\n",
    "    classElem_btn.click()\n",
    "\n",
    "    # 填写密码\n",
    "    Elem_input = browser.find_elements_by_tag_name('input')\n",
    "    for t in Elem_input:\n",
    "        print(t.get_property('name'))\n",
    "    passwordElem = Elem_input[2]      \n",
    "    passwordElem.send_keys(password)\n",
    "\n",
    "    # 点击下一步\n",
    "    classElem_btn = browser.find_element_by_class_name('RveJvd')\n",
    "    classElem_btn.click()\n",
    "    \n",
    "email = getpass.getpass('Input your email account: ')\n",
    "password = getpass.getpass('Input your password: ') #不显示输入值\n",
    "gmailSignin(email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
