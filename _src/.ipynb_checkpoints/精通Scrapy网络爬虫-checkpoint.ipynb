{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython输出各行结果\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精通Scrapy网络爬虫\n",
    "\n",
    "作者: 刘硕  \n",
    "出版社: 清华大学出版社  \n",
    "出版年: 2017-10-1  \n",
    "定价: 59元  \n",
    "\n",
    " `scrapy`模块\n",
    " \n",
    "据说它的seletor结合BeautifulSoup&lxml的双重优点，比lxml易用，比bs4快。\n",
    "\n",
    "selector的过程是先选中后提取。选中靠selector，提取靠extract。只要不提取，就可以一层一层选下去。\n",
    "\n",
    "终于明白了re和selector结合应用的地方：selector**提取出来的内容**，如果**还需要拆分，使用re**。而不是用re去解析html。\n",
    "\n",
    "### 1.1 选择器：xpath和css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Click here to go to the next page']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['<p class=\"small info\">Hello world</p>']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xpath\n",
    "import scrapy\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "text = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <base href='http://example.com/' />\n",
    "        <title>Example WebSite</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1> Hello World</h1>\n",
    "        <h1> Hello Scrapy</h1>\n",
    "        <b> Hello Python</b>\n",
    "        <a href=\"#\">Click here to go to the <strong>next page</strong></a>\n",
    "        <ul>\n",
    "            <li>C++</li>\n",
    "            <li>Java</li>\n",
    "            <li>Python</li>\n",
    "            <li>Python 学习手册 <b>价格：99.00元 </b></li>\n",
    "            <li>Python 核心编程 <b>价格：88.00元 </b></li>\n",
    "            <li>Python 基础教程 <b>价格：80.00元 </b></li>\n",
    "        </ul>\n",
    "        <div id='images'>\n",
    "            <a href='image1.html' class='image'>Name: Image 1<br/><img src='image1.jpg' /></a>\n",
    "            <a href='image2.html'>Name: Image 2<br/><img src='image2.jpg' /></a>\n",
    "            <a href='image3.html'>Name: Image 3<br/><img src='image3.jpg' /></a>\n",
    "            <a href='image4.html'>Name: Image 4<br/><img src='image4.jpg' /></a>\n",
    "            <a href='image5.html'>Name: Image 5<br/><img src='image5.jpg' /></a>\n",
    "        </div>\n",
    "        <div>\n",
    "            <p class=\"small info\">Hello world</p>\n",
    "            <p class=\"normal info\">Hello scrapy</p>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "selector = Selector(text=text)\n",
    "# selector.xpath('//h1') # 选中所有h1标签\n",
    "# for sel in selector.xpath('//h1'):\n",
    "#     print(sel.xpath('./text()'))\n",
    "# selector.xpath('//li').xpath('./text()').extract_first() # 三者等价\n",
    "# selector.xpath('//li').xpath('./text()')[0].extract() # 三者等价\n",
    "# selector.xpath('//li/text()').extract_first() # 三者等价\n",
    "# selector.xpath('string(//li[4])').extract()\n",
    "# selector.xpath('//li/b/text()').re('\\d+\\.\\d+')\n",
    "\n",
    "response = HtmlResponse(url='http://example.com', body=text, encoding='utf8')\n",
    "# sel = response.selector # 二者等价\n",
    "# sel = Selector(response=response) # 二者等价\n",
    "# response.xpath('//li/b/text()').extract()\n",
    "# response.xpath('//a[@href=\"image1.html\"]')\n",
    "# response.xpath('//div//*')\n",
    "# response.xpath('//img/@src')\n",
    "# response.xpath('//a[1]/@*')\n",
    "# response.xpath('//a[position()<=3]')\n",
    "response.xpath('string(//a)').extract() # string()只认第一个。\n",
    "response.xpath('//p[contains(@class, \"small\")]').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='descendant-or-self::a[count(preceding-sibling::*) = 1]/text()' data='Name: Image 2'>,\n",
       " <Selector xpath='descendant-or-self::a[count(preceding-sibling::*) = 1]/text()' data='Name: Image 5'>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# css\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "body = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <base href='http://example.com/' />\n",
    "        <title>Example WebSite</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div id='images-1' style=\"width: 123px;\">\n",
    "            <a href='image1.html'>Name: Image 1<br/><img src='image1.jpg' /></a>\n",
    "            <a href='image2.html'>Name: Image 2<br/><img src='image2.jpg' /></a>\n",
    "            <a href='image3.html'>Name: Image 3<br/><img src='image3.jpg' /></a>\n",
    "        </div>\n",
    "        <div id='images-2' class='small'>\n",
    "            <a href='image4.html'>Name: Image 4<br/><img src='image4.jpg' /></a>\n",
    "            <a href='image5.html'>Name: Image 5<br/><img src='image5.jpg' /></a>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "response = HtmlResponse(url='http://www.example.com', body=body, encoding='utf8')\n",
    "# response.css('div>a:nth-child(1)') # 每个div中的第一个\n",
    "# response.css('div:nth-child(2)>a:nth-child(1)') # 也是从1开始计数\n",
    "# response.css('div:first-child>a:last-child')\n",
    "response.css('a:nth-child(2)::text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tipping the Velvet'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Tipping the Velvet'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Tipping the Velvet'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "url = 'http://books.toscrape.com/'\n",
    "res = requests.get(url)\n",
    "\n",
    "# 用lxml\n",
    "selector = etree.HTML(res.text)\n",
    "selector.xpath('//h3/a/text()')[1] # 不需要也不能使用extract()\n",
    "\n",
    "# 用scrapy的Selector\n",
    "selector = Selector(text=res.text)\n",
    "selector.xpath('//h3/a/text()')[1].extract()\n",
    "\n",
    "# 用scrapy的HtmlResponse\n",
    "response = HtmlResponse(url=url, body=res.text, encoding='utf8') # 三个参数缺一不可。\n",
    "response.xpath('//h3/a/text()')[1].extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "url = 'http://books.toscrape.com/'\n",
    "res = requests.get(url)\n",
    "\n",
    "sel = Selector(text=res.text)\n",
    "sel.xpath('//li[@class=\"next\"]/a/@href').extract_first()\n",
    "nextUrl = sel.css('li.next a::attr(href)').extract_first()\n",
    "response = HtmlResponse(url=url, body=res.text, encoding='utf8')\n",
    "response.url\n",
    "response.urljoin(nextUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Item封装数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Little Prince', 'price': 45.0}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Life of pi', 'price': 32.5}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ItemsView({'name': 'Little Prince', 'price': 45.0})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scrapy import Item, Field\n",
    "\n",
    "class BookItem(Item):\n",
    "    name = Field()\n",
    "    price = Field()\n",
    "    \n",
    "book1 = BookItem(name='Little Prince', price=45.0)\n",
    "book1\n",
    "book2 = BookItem()\n",
    "book2['name'] = 'Life of pi'\n",
    "book2['price'] = 32.5\n",
    "book2\n",
    "book1.get('price',60.0) # 估计类似于字典的默认值。\n",
    "book1.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scrapy import Item, Field\n",
    "\n",
    "class BookItem(Item):\n",
    "    name = Field()\n",
    "    price = Field()\n",
    "    \n",
    "book = BookItem()\n",
    "book['name'] = '安徒生童话'\n",
    "book['price'] = '$23'\n",
    "\n",
    "class ForeignBookItem(BookItem):\n",
    "    translator = Field()\n",
    "    \n",
    "book1 = ForeignBookItem()\n",
    "book1['name'] = '大卫不可以'\n",
    "book1['price'] = '$15'\n",
    "book1['translator'] = '任溶溶'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleItem(Item):\n",
    "    x = Field(a='hello', b=[1,2,3])\n",
    "    y = Field(a=lambda x:x**2)\n",
    "e = ExampleItem(x=100, y=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'a': 'hello', 'b': [1, 2, 3]},\n",
       " 'y': {'a': <function __main__.ExampleItem.<lambda>(x)>}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'a': 'hello', 'b': [1, 2, 3]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scrapy.item.Field"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.ExampleItem.<lambda>(x)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.fields\n",
    "issubclass(Field, dict)\n",
    "e['x']\n",
    "e.fields['x']\n",
    "type(e.fields['x'])\n",
    "e.fields['x']['a']\n",
    "\n",
    "e.fields['y'].get('a', lambda x:x**2) # 看不懂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 LinkExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div id=\"top\">\n",
    "            <p>下面是一些站内链接</p>\n",
    "            <a class=\"internal\" href=\"/intro/install.html\">Installation guide</a>\n",
    "            <a class=\"internal\" href=\"/intro/tutorial.html\">Tutorial</a>\n",
    "            <a class=\"internal\" href=\"../examples.html\">Examples</a>\n",
    "        </div>\n",
    "        <div id=\"bottom\">\n",
    "            <p>下面是一些站外链接</p>\n",
    "            <a href=\"http://stackoverflow.com/tags/scrapy/info\">StackOverflow</a>\n",
    "            <a href=\"http://github.com/scrapy/scrapy\">Fork on Github</a>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "\n",
    "'''\n",
    "example2 = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <script type=\"text/javascript\" src=\"/js/app1.js\">\n",
    "        <script type=\"text/javascript\" src=\"/js/app2.js\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <a href=\"/home.html\">主页</a>\n",
    "        <a href=\"javascript:goToPage('/doc.html'; return false)\">文档</a>\n",
    "        <a href=\"javascript:goToPage('/example.html'; return false)\">案例</a>\n",
    "    </body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://example2.html/js/app1.js']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scrapy.http import HtmlResponse\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "response1 = HtmlResponse(url=\"http://example1.html\", body=example1, encoding=\"utf8\")\n",
    "response2 = HtmlResponse(url=\"http://example2.html\", body=example2, encoding=\"utf8\")\n",
    "\n",
    "# pattern = '/intro/.+\\.html$'\n",
    "# pattern = '^' + urlparse(response1.url).geturl() # 突然发现urlparse(response1.url).geturl()和response1.url结果相同。\n",
    "# domains = ['github.com', 'stackoverflow.com']\n",
    "# le = LinkExtractor(deny=pattern)\n",
    "# le = LinkExtractor(deny_domains=domains)\n",
    "# le = LinkExtractor(restrict_xpaths='//div[@id=\"bottom\"]')\n",
    "# le = LinkExtractor(restrict_css='div#top')\n",
    "# links = le.extract_links(response1)\n",
    "le = LinkExtractor(tags='script', attrs='src') # 为什么结果不是两个？\n",
    "links = le.extract_links(response2)\n",
    "[link.url for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def process(value):\n",
    "    m = re.search('javascript:goToPage\\(\"(.*?)\")', value)\n",
    "    if m:\n",
    "        value = m.group(1)\n",
    "    return value\n",
    "\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "le = LinkExtractor(process_value=process)\n",
    "links = le.extract_links(response2)\n",
    "[link.url for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
